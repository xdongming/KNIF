{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 08:31:22.226813: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-09 08:31:22.242435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-09 08:31:22.260205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-09 08:31:22.265413: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-09 08:31:22.278650: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "from koopmanlib.dictionary import PsiNN\n",
    "from koopmanlib.solver import KoopmanDLSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 6\n",
    "hidden_dim = 80\n",
    "input_dim = 6\n",
    "n_feature = 14\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "n_train = 6660\n",
    "n_test = 606\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5c67d8-35ba-439c-a7ca-a6c388c65c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('robot_X_train.csv', header=None).values\n",
    "X_test = pd.read_csv('robot_X_test.csv', header=None).values\n",
    "U_train = pd.read_csv('robot_U_train.csv', header=None).values\n",
    "U_test = pd.read_csv('robot_U_test.csv', header=None).values\n",
    "\n",
    "length = X_train.shape[1] // n_train\n",
    "HX_train = []\n",
    "HU_train = []\n",
    "for i in range(n_train):\n",
    "    HX_train.append(X_train[:, i*length:(i+1)*length])\n",
    "    HU_train.append(U_train[:, i*length:(i+1)*length])\n",
    "HX_train = np.stack([HX_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HU_train = np.stack([HU_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HX_test = []\n",
    "HU_test = []\n",
    "for i in range(n_test):\n",
    "    HX_test.append(X_test[:, i*length:(i+1)*length])\n",
    "    HU_test.append(U_test[:, i*length:(i+1)*length])\n",
    "HX_test = np.stack([HX_test[idx].T for idx in range(n_test)], axis=0)\n",
    "HU_test = np.stack([HU_test[idx].T for idx in range(n_test)], axis=0)\n",
    "\n",
    "H_train = np.concatenate([HX_train, HU_train], axis=-1)\n",
    "H_test = np.concatenate([HX_test, HU_test], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31b4457-3c72-40df-b3ee-036020940634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 08:31:33.053430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78904 MB memory:  -> device: 0, name: NVIDIA H100 80GB HBM3, pci bus id: 0000:3a:00.0, compute capability: 9.0\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'psi_nn_layer', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "2025-06-09 08:31:34.820242: I tensorflow/core/util/cuda_solvers.cc:178] Creating GpuSolver handles for stream 0x9ff9fc0\n",
      "2025-06-09 08:31:35.487638: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Matrix size-incompatible: In[0]: [33,6660], In[1]: [0,33]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Matrix size-incompatible: In[0]: [33,6660], In[1]: [0,33] [Op:MatMul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m basis_function = PsiNN(layer_sizes=[hidden_dim, hidden_dim, hidden_dim], n_psi_train=dim+n_feature)\n\u001b[32m      6\u001b[39m solver = KoopmanDLSolver(dic=basis_function,\n\u001b[32m      7\u001b[39m                         target_dim=dim+input_dim,\n\u001b[32m      8\u001b[39m                         reg=\u001b[32m0.0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mdata_valid\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mlr_decay_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.92\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_test):\n\u001b[32m     17\u001b[39m     x_traj = H_test[j, \u001b[32m0\u001b[39m:\u001b[32m6\u001b[39m*i:i,:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/ws-f4d69b29-e0a5-44e6-bd92-acf4de9990f0/public-project/xiedongming-240108110055/Normalizing Flows/Real Robustness/koopmanlib/solver.py:214\u001b[39m, in \u001b[36mKoopmanDLSolver.build\u001b[39m\u001b[34m(self, data_train, data_valid, epochs, batch_size, lr, log_interval, lr_decay_factor)\u001b[39m\n\u001b[32m    211\u001b[39m losses = []\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# One step for computing K\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28mself\u001b[39m.K = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_K\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdic_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_x_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_y_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.get_layer(\u001b[33m'\u001b[39m\u001b[33mLayer_K\u001b[39m\u001b[33m'\u001b[39m).weights[\u001b[32m0\u001b[39m].assign(\u001b[38;5;28mself\u001b[39m.K)\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# Two steps for training PsiNN\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/inspire/hdd/ws-f4d69b29-e0a5-44e6-bd92-acf4de9990f0/public-project/xiedongming-240108110055/Normalizing Flows/Real Robustness/koopmanlib/solver.py:99\u001b[39m, in \u001b[36mKoopmanGeneralSolver.compute_K\u001b[39m\u001b[34m(self, dic, data_x, data_y, reg)\u001b[39m\n\u001b[32m     97\u001b[39m idmat = tf.eye(psi_x.shape[-\u001b[32m1\u001b[39m], dtype=\u001b[33m'\u001b[39m\u001b[33mfloat64\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     98\u001b[39m xtx_inv = tf.linalg.pinv(reg * idmat + tf.matmul(psi_xt, psi_x))\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m xty = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_xt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28mself\u001b[39m.K_reg = tf.matmul(xtx_inv, xty)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.K_reg\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[39m, in \u001b[36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    141\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m   bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m   bound_arguments.apply_defaults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py:5983\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   5982\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m5983\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:GPU:0}} Matrix size-incompatible: In[0]: [33,6660], In[1]: [0,33] [Op:MatMul] name: "
     ]
    }
   ],
   "source": [
    "error_temp = []\n",
    "\n",
    "data_train = [H_train[:, 0:5,:].reshape(-1, dim+input_dim), H_train[:, 1:6,:].reshape(-1, dim+input_dim)]\n",
    "data_valid = [H_train[:, 0:5,:].reshape(-1, dim+input_dim), H_train[:, 1:6,:].reshape(-1, dim+input_dim)]\n",
    "basis_function = PsiNN(layer_sizes=[hidden_dim, hidden_dim, hidden_dim], n_psi_train=dim+n_feature)\n",
    "solver = KoopmanDLSolver(dic=basis_function,\n",
    "                        target_dim=dim+input_dim,\n",
    "                        reg=0.0)\n",
    "solver.build(data_train=data_train,\n",
    "                 data_valid=data_valid,\n",
    "                 epochs=num_epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 lr=learning_rate,\n",
    "                 log_interval=1,\n",
    "                 lr_decay_factor=0.92)\n",
    "for j in range(n_test):\n",
    "    x_traj = H_test[j, 0:6,:]\n",
    "    x0_test = x_traj[0]\n",
    "    x0_test = x0_test.reshape(-1, x0_test.shape[-1])\n",
    "    x_est_traj_DL = solver.predict(x0_test, 5)\n",
    "    error_temp.append((x_est_traj_DL[:, :dim]-x_traj[1:, :dim]) ** 2)\n",
    "error = np.mean(np.array(error_temp))\n",
    "    \n",
    "df = pd.DataFrame([error])\n",
    "df.to_csv(\"Robot_EDMDDL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5134d4e-80c9-4e0b-b8e9-fd2989b561d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
