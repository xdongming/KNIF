{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import math\n",
    "from pydmd import DMD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from matplotlib.font_manager import FontProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a57628-6d4f-47de-842f-e5d20fae90a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualFlow(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_layers, input_dim=0, dropout=0, LDJ=False, block_id=0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_dim = input_dim\n",
    "        self.LDJ = LDJ\n",
    "        self.block_id = block_id\n",
    "\n",
    "        flip = (block_id % 2 == 0)\n",
    "        self.flow = Flow(dim, hidden_dim, flip=flip)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        x_e = x\n",
    "        if not reverse:\n",
    "            y = self.flow(x_e, reverse=False)\n",
    "            logdet = 0\n",
    "            return y, logdet\n",
    "        else:\n",
    "            y = self.flow(x_e, reverse=True)\n",
    "            return y\n",
    "\n",
    "class Flow(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_dim, flip=False):\n",
    "        super().__init__()\n",
    "        self.coupling = AffineCoupling(in_channel, hidden_dim, flip)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        return self.coupling(x, reverse)\n",
    "\n",
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, flip=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.flip = flip\n",
    "\n",
    "        self.split_idx = dim // 2\n",
    "        self.rest_dim = dim - self.split_idx\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.split_idx, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.rest_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        if self.flip:\n",
    "            x2, x1 = torch.split(x, [self.rest_dim, self.split_idx], dim=-1)\n",
    "        else:\n",
    "            x1, x2 = torch.split(x, [self.split_idx, self.rest_dim], dim=-1)\n",
    "\n",
    "        h = self.net(x1)\n",
    "        s, t = torch.chunk(h, 2, dim=-1)\n",
    "        s = torch.tanh(s)\n",
    "\n",
    "        if not reverse:\n",
    "            y2 = x2 * torch.exp(s) + t\n",
    "        else:\n",
    "            y2 = (x2 - t) * torch.exp(-s)\n",
    "\n",
    "        if self.flip:\n",
    "            return torch.cat([y2, x1], dim=-1)\n",
    "        else:\n",
    "            return torch.cat([x1, y2], dim=-1)\n",
    "    \n",
    "class InvertibleNN(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_blocks, n_layers, input_dim=0, dropout=0, LDJ=False):\n",
    "        super(InvertibleNN, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        self.blocks = nn.ModuleList([ResidualFlow(self.dim, self.hidden_dim, self.n_layers, self.input_dim, dropout, LDJ, block_id=i) for i in range(self.n_blocks)])\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        if not reverse:\n",
    "            ldj_total = 0\n",
    "            for block in self.blocks:\n",
    "                x, ldj = block(x, reverse)\n",
    "                ldj_total += ldj\n",
    "            return x, ldj_total\n",
    "        else:\n",
    "            for block in reversed(self.blocks):\n",
    "                x = block(x, reverse)\n",
    "            return x\n",
    "    \n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, inn_model, input_dim, lifted_dim):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.inn_model = inn_model  \n",
    "        self.lifted_dim = lifted_dim\n",
    "        self.K = nn.Parameter(torch.randn(input_dim + lifted_dim, input_dim + lifted_dim), requires_grad=True)\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        x = x.float()\n",
    "        if not reverse:\n",
    "            zero_pad = torch.zeros(x.shape[0], x.shape[1], self.lifted_dim, device=x.device)\n",
    "            x = torch.cat((x, zero_pad), dim=-1)\n",
    "            x, ldj = self.inn_model(x, u, reverse)\n",
    "            return x, ldj\n",
    "        else:\n",
    "            x = self.inn_model(x, u, reverse)\n",
    "            x = x[:, :self.input_dim]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8996c880-1612-417a-ade9-b294f93ad045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dmd(model, X):\n",
    "    GX_pred_list = []\n",
    "    GX_list = []\n",
    "    GX, ldj = model(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        GX_temp = GX[i, :, :].T\n",
    "        GX_pred = model.K @ GX_temp[:, :-1]\n",
    "        GX_pred_list.append(GX_pred)\n",
    "        GX_list.append(GX_temp[:, 1:])\n",
    "    GX_pred = torch.cat(GX_pred_list, dim=-1)\n",
    "    GX = torch.cat(GX_list, dim=1)\n",
    "\n",
    "    return GX, GX_pred, ldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bede68be-e48a-4205-b695-7cc047d892cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "    def __init__(self, model, train_dataset, learning_rate=1e-3, lamb=1, path=\"model_checkpoint_NP\"):\n",
    "        super(TrainModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.best_val_loss = float('inf')  \n",
    "        self.validation_outputs = []\n",
    "        self.lamb = lamb\n",
    "        self.train_losses = []\n",
    "        self.path = path+'.ckpt'\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch = batch[0]\n",
    "        GY, GY_pred, ldj = dmd(self.model, X_batch)\n",
    "\n",
    "        loss_lin = self.criterion(GY, GY_pred.detach())\n",
    "        loss_LDJ = ldj / X_batch.numel()\n",
    "\n",
    "        loss = loss_lin - self.lamb * loss_LDJ\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, _ = dmd(self.model, Z_batch)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, reverse=True)\n",
    "        valid_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.validation_outputs.append(valid_loss)\n",
    "        self.log('val_loss', valid_loss)\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, _ = dmd(self.model, Z_batch)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, reverse=True)\n",
    "        test_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.log('test_loss', test_loss)\n",
    "        return test_loss\n",
    "    \n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        with torch.no_grad():  \n",
    "            for name, module in self.model.named_modules():  \n",
    "                if isinstance(module, nn.Linear): \n",
    "                    if name == \"linear\":  \n",
    "                        continue\n",
    "                    weight = module.weight  \n",
    "                    sigma_max = torch.linalg.norm(weight, ord=2)  \n",
    "                    if sigma_max >= 1 - 1e-2:  \n",
    "                        scale = (1 - 1e-2) / sigma_max\n",
    "                        module.weight.data *= scale\n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        if os.path.exists(self.path):\n",
    "            best_state_dict = torch.load(self.path)[\"state_dict\"]\n",
    "            self.load_state_dict(best_state_dict)\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        device = self.model.K.device\n",
    "        self.model.eval() \n",
    "        with torch.no_grad():\n",
    "            x_all = self.train_dataset.tensors[0].to(device)  \n",
    "\n",
    "            gx_all = self.model(x_all)[0].detach()[:, :-1, :] \n",
    "            gy_all = self.model(x_all)[0].detach()[:, 1:, :]\n",
    "\n",
    "            gx_all = gx_all.reshape(-1, gx_all.shape[-1])\n",
    "            gy_all = gy_all.reshape(-1, gy_all.shape[-1])\n",
    "\n",
    "        optimizer_K = torch.optim.Adam([self.model.K], lr=1e-3)\n",
    "        for _ in range(100):  \n",
    "            optimizer_K.zero_grad()\n",
    "            gx_pred = gx_all @ self.model.K\n",
    "            loss_K = self.criterion(gx_pred, gy_all)\n",
    "            loss_K.backward()\n",
    "            optimizer_K.step()\n",
    "            with torch.no_grad():\n",
    "                radius = torch.linalg.norm(self.model.K.data, ord=2)\n",
    "                if radius > 1.0:\n",
    "                    self.model.K.data /= radius\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_outputs).mean()\n",
    "        self.log('avg_val_loss', avg_val_loss)\n",
    "        self.validation_outputs.clear()\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        with open(\"loss_log.txt\", \"a\") as f:\n",
    "            f.write(f\"{avg_val_loss.item()}\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        g_params = [p for n, p in self.model.named_parameters() if \"K\" not in n]\n",
    "        optimizer = torch.optim.AdamW(g_params, lr=self.learning_rate, weight_decay=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=100,\n",
    "            gamma=0.5\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\", \n",
    "            },\n",
    "            \"gradient_clip_val\": 1.0, \n",
    "            \"gradient_clip_algorithm\": \"norm\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 8 \n",
    "hidden_dim = 80  \n",
    "input_dim = 0\n",
    "n_blocks = 20 \n",
    "n_feature = 12\n",
    "rank = 20\n",
    "batch_size = 1\n",
    "# n_train = 6400\n",
    "n_train = 1\n",
    "# n_valid = 1000\n",
    "n_test = 1\n",
    "dropout = 0\n",
    "num_epochs = 9999  \n",
    "lamb = 1e-3\n",
    "learning_rate = 1e-3 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6874831a-16e4-4744-8cc9-1cf2c819a392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('y_train.csv', header=None).values.astype(float)\n",
    "length = X_train.shape[1] // n_train\n",
    "H_train = []\n",
    "for i in range(n_train):\n",
    "    H_train.append(X_train[:, i*length:(i+1)*length])\n",
    "H_train = np.stack([H_train[idx].T for idx in range(n_train)], axis=0)\n",
    "train_dataset = TensorDataset(torch.tensor(H_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8abde0b2-c523-4bad-830f-ae0a236d0f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "inn_model = InvertibleNN(dim=dim+input_dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=1, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim+input_dim, lifted_dim=n_feature)\n",
    "path = \"model_checkpoint_Wave_flowdmd.ckpt\"\n",
    "lightning_model = TrainModel.load_from_checkpoint(path, model=model, train_dataset=train_dataset, learning_rate=learning_rate, map_location=\"cpu\")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b65bcc7-4cda-4e60-8fe3-8b08b994f587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss         1.2458720448194072e-05\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.2458720448194072e-05}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.test(lightning_model, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2349e24-07eb-4ab9-8eba-c5436072c26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "X_traj = H_train\n",
    "GY, GY_pred, _ = dmd(lightning_model.model, torch.tensor(X_traj, dtype=torch.float32))\n",
    "X_recons = lightning_model.model(GY_pred.T.cpu(), reverse=True).T.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c5cd331-df15-4a81-a737-1672b6ebf9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2620, 10, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e3fe170-0aba-4cf2-85fb-c09a7c789d93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "t = np.linspace(0.01, 0.61, num=length-1)\n",
    "median_traj = X_recons\n",
    "\n",
    "interp_factor = 10\n",
    "t_new = np.linspace(t.min(), t.max(), len(t) * interp_factor)\n",
    "\n",
    "f_med = interp1d(t, median_traj[1, :], kind='cubic')\n",
    "\n",
    "smooth_median = f_med(t_new)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "plt.plot(t_new[::18], smooth_median[::18], color=\"#4878CF\", linewidth=1.5, label='Median')\n",
    "\n",
    "plt.scatter(t[::18], X_traj[0, 1:length:18, 0], color='#D65F5F', s=8, linewidths=1.0, label='Test')\n",
    "\n",
    "# plt.plot(smooth_x, smooth_y, color=\"#0072B2\", linewidth=1.5, label='Reconstructed', zorder=1)\n",
    "\n",
    "# plt.scatter(\n",
    "#     t, X_traj[0, 1:751, 0]\n",
    "#     facecolors='none',\n",
    "#     edgecolors='#DAA520',\n",
    "#     s=30,\n",
    "#     linewidth=1.5,\n",
    "#     label='Test',\n",
    "#     zorder=2\n",
    "# )\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"f3.svg\", format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
