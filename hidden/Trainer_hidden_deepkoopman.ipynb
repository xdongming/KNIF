{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import math\n",
    "from pydmd import DMD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2a57628-6d4f-47de-842f-e5d20fae90a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim=128, n_layers=2, activation=nn.ReLU):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, hidden_dim), activation()]\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.extend([nn.Linear(hidden_dim, hidden_dim), activation()])\n",
    "        layers.append(nn.Linear(hidden_dim, out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim=128, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.net = MLP(input_dim, latent_dim, hidden_dim, n_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim, hidden_dim=128, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.net = MLP(latent_dim, output_dim, hidden_dim, n_layers)\n",
    "\n",
    "    def forward(self, y):\n",
    "        return self.net(y)\n",
    "    \n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, num_visible, num_hidden, hidden_size=32, kernel_size=31):\n",
    "        super().__init__()\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_visible, out_channels=hidden_size, kernel_size=kernel_size)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=hidden_size, out_channels=num_hidden, kernel_size=1)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.tanh(self.conv3(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "        \n",
    "class AuxiliaryKoopmanNet(nn.Module):\n",
    "    def __init__(self, in_dim, koopman_type='complex', hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.koopman_type = koopman_type\n",
    "        out_dim = 2 if koopman_type == 'complex' else 1\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, y):\n",
    "        out = self.net(y)\n",
    "        if self.koopman_type == 'complex':\n",
    "            mu, omega = out[:, 0], out[:, 1]\n",
    "            return mu, omega\n",
    "        else:\n",
    "            mu = out.squeeze(-1)\n",
    "            return mu, None\n",
    "\n",
    "def build_koopman_matrix(mu, omega):\n",
    "    batch_size = mu.shape[0]\n",
    "    dt = 1.0\n",
    "    exp_mu = torch.exp(mu * dt)\n",
    "    if omega is not None:\n",
    "        cos_ = torch.cos(omega * dt)\n",
    "        sin_ = torch.sin(omega * dt)\n",
    "        K_blocks = torch.zeros(batch_size, 2, 2).to(mu.device)\n",
    "        K_blocks[:, 0, 0] = exp_mu * cos_\n",
    "        K_blocks[:, 0, 1] = -exp_mu * sin_\n",
    "        K_blocks[:, 1, 0] = exp_mu * sin_\n",
    "        K_blocks[:, 1, 1] = exp_mu * cos_\n",
    "    else:\n",
    "        K_blocks = torch.eye(2).unsqueeze(0).repeat(batch_size, 1, 1).to(mu.device)\n",
    "        K_blocks = exp_mu.view(-1, 1, 1) * K_blocks\n",
    "    return K_blocks\n",
    "\n",
    "class DeepKoopman(nn.Module):\n",
    "    def __init__(self, input_dim, num_real, num_complex,\n",
    "                 hidden_dim=128, n_layers=2,\n",
    "                 visible_dim=2, kernel_size=31, num_hidden=1):\n",
    "        super().__init__()\n",
    "        self.num_real = num_real\n",
    "        self.num_complex = num_complex\n",
    "        self.latent_dim = num_real * 1 + num_complex * 2\n",
    "        self.visible_dim = visible_dim\n",
    "        self.num_hidden = num_hidden\n",
    "        self.encoder = Encoder(visible_dim + num_hidden, self.latent_dim, hidden_dim, n_layers)\n",
    "        self.extra_encoder = ConvEncoder(visible_dim, num_hidden,\n",
    "                                         hidden_size=hidden_dim, kernel_size=kernel_size)\n",
    "        self.decoder = Decoder(self.latent_dim, visible_dim, hidden_dim, n_layers)\n",
    "        self.aux_nets = nn.ModuleList()\n",
    "        for _ in range(num_real):\n",
    "            self.aux_nets.append(AuxiliaryKoopmanNet(in_dim=1, koopman_type='real'))\n",
    "        for _ in range(num_complex):\n",
    "            self.aux_nets.append(AuxiliaryKoopmanNet(in_dim=2, koopman_type='complex'))\n",
    "\n",
    "    def split_latent(self, z):\n",
    "        idx = 0\n",
    "        parts = []\n",
    "        for _ in range(self.num_real):\n",
    "            parts.append(z[:, idx:idx+1])   # [B,1]\n",
    "            idx += 1\n",
    "        for _ in range(self.num_complex):\n",
    "            parts.append(z[:, idx:idx+2])   # [B,2]\n",
    "            idx += 2\n",
    "        return parts\n",
    "\n",
    "    def koopman_step(self, z):\n",
    "        if z.dim() == 3:\n",
    "            B, T, D = z.shape\n",
    "            z = z.reshape(B*T, D)\n",
    "            zs = self.split_latent(z)  \n",
    "            updated = []\n",
    "            for sub_z, net in zip(zs, self.aux_nets):\n",
    "                mu, omega = net(sub_z)\n",
    "                if sub_z.shape[1] == 1:\n",
    "                    z_next = mu.unsqueeze(-1) * sub_z\n",
    "                else:\n",
    "                    Btot = sub_z.shape[0]\n",
    "                    Bmat = build_koopman_matrix(mu, omega)   # [B*T,2,2]\n",
    "                    z_rot = torch.bmm(Bmat, sub_z.unsqueeze(-1)).squeeze(-1)\n",
    "                    z_next = z_rot\n",
    "                updated.append(z_next)\n",
    "            z_new = torch.cat(updated, dim=-1).reshape(B, T, -1)\n",
    "        else:\n",
    "            zs = self.split_latent(z)   # [B,1]/[B,2]\n",
    "            updated = []\n",
    "            for sub_z, net in zip(zs, self.aux_nets):\n",
    "                mu, omega = net(sub_z)\n",
    "                if sub_z.shape[1] == 1:\n",
    "                    z_next = mu.unsqueeze(-1) * sub_z\n",
    "                else:\n",
    "                    B = sub_z.shape[0]\n",
    "                    Bmat = build_koopman_matrix(mu, omega)\n",
    "                    z_rot = torch.bmm(Bmat, sub_z.unsqueeze(-1)).squeeze(-1)\n",
    "                    z_next = z_rot\n",
    "                updated.append(z_next)\n",
    "            z_new = torch.cat(updated, dim=-1)\n",
    "        return z_new\n",
    "\n",
    "    def koopman_power(self, z, m):\n",
    "        for _ in range(m):\n",
    "            z = self.koopman_step(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, steps=1, reverse=False):\n",
    "        if reverse:\n",
    "            raise NotImplementedError(\"Reverse is not used here.\")\n",
    "        interval = (self.extra_encoder.kernel_size - 1) // 2\n",
    "        x_vis = x[:, interval:-interval, :self.visible_dim]        # [B, T', V]\n",
    "        x_hid = self.extra_encoder(x[:, :, :self.visible_dim])     # [B, T', H]\n",
    "        x_aug = torch.cat([x_vis, x_hid], dim=-1)\n",
    "        z0 = self.encoder(x_aug)\n",
    "        z1 = self.koopman_power(z0, steps)\n",
    "        x_pred = self.decoder(z1)                                  # [B, T', V]\n",
    "\n",
    "        return x_pred, z0, z1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8996c880-1612-417a-ade9-b294f93ad045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def koopman_rollout_prediction(model, X):\n",
    "    \"\"\"\n",
    "    Koopman rollout prediction over full sequence length T.\n",
    "\n",
    "    Args:\n",
    "        X: shape [B, T, dim]\n",
    "    Returns:\n",
    "        x_preds: shape [B, T, dim]\n",
    "        y_preds: shape [B, T, latent_dim]\n",
    "    \"\"\"\n",
    "    B, T, dim = X.shape\n",
    "    x0 = X[:, 0, :] \n",
    "    y = model.encoder(x0)  # [B, latent_dim]\n",
    "\n",
    "    x_preds = []\n",
    "    y_preds = []\n",
    "\n",
    "    for t in range(T):\n",
    "        x_hat = model.decoder(y)\n",
    "        x_preds.append(x_hat)\n",
    "        y_preds.append(y)\n",
    "\n",
    "        mu, omega = model.aux_net(y)\n",
    "        K = build_koopman_matrix(mu, omega)  # [B, 2, 2]\n",
    "\n",
    "        y_next = y.clone()\n",
    "        y_rot = torch.bmm(K, y[:, :2].unsqueeze(-1)).squeeze(-1)\n",
    "        y_next[:, :2] = y_rot\n",
    "        y = y_next\n",
    "\n",
    "    x_preds = torch.stack(x_preds, dim=1)  # [B, T, dim]\n",
    "    y_preds = torch.stack(y_preds, dim=1)  # [B, T, latent_dim]\n",
    "    return x_preds, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bede68be-e48a-4205-b695-7cc047d892cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3,\n",
    "                 alpha1=0.1, alpha2=1e-7, alpha3=1e-13, \n",
    "                 path=\"deepkoop_ckpt\"):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.alpha1 = alpha1\n",
    "        self.alpha2 = alpha2\n",
    "        self.alpha3 = alpha3\n",
    "        self.criterion_mse = nn.MSELoss()\n",
    "        self.criterion_linf = lambda a, b: torch.max(torch.abs(a - b))\n",
    "        self.path = path + \".ckpt\"\n",
    "\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "        self.validation_outputs = []\n",
    "        self.train_losses = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, T, visible_dim]\n",
    "        \"\"\"\n",
    "        B, T, V = x.shape\n",
    "        interval = (self.model.extra_encoder.kernel_size - 1) // 2\n",
    "        target = x[:, interval:-interval, :self.model.visible_dim]  # [B, T', V]\n",
    "        T_prime = target.shape[1]\n",
    "\n",
    "        x_pred, z0, z1 = self.model(x, steps=1)   # x_pred: [B,T',V], z0: [B,T',D]\n",
    "\n",
    "        # Reconstruction Loss\n",
    "        B, T_prime, D = z0.shape\n",
    "        x_recon = self.model.decoder(z0.reshape(B * T_prime, D)).reshape(B, T_prime, -1)\n",
    "        L_recon = self.criterion_mse(target, x_recon)\n",
    "\n",
    "        # Future Prediction Loss\n",
    "        L_pred = 0\n",
    "        z_init = z0[:, 0, :]   \n",
    "        for m in range(1, T_prime):\n",
    "            z_pred = self.model.koopman_power(z_init, m)     # [B,D]\n",
    "            x_m = self.model.decoder(z_pred)                 # [B,V]\n",
    "            L_pred += self.criterion_mse(target[:, m], x_m)\n",
    "        L_pred /= (T_prime - 1)\n",
    "\n",
    "        # Linearity Loss\n",
    "        L_lin = 0\n",
    "        for m in range(T_prime - 1):\n",
    "            z_next_pred = self.model.koopman_step(z0[:, m])  # [B,D] → [B,D]\n",
    "            L_lin += self.criterion_mse(z0[:, m + 1], z_next_pred)\n",
    "        L_lin /= (T_prime - 1)\n",
    "\n",
    "        # L_inf Loss\n",
    "        x1 = target[:, 0]\n",
    "        x1_recon = x_recon[:, 0]\n",
    "        x2 = target[:, 1]\n",
    "        x2_pred = self.model.decoder(self.model.koopman_power(z_init, 1))\n",
    "        L_inf = self.criterion_linf(x1, x1_recon) + self.criterion_linf(x2, x2_pred)\n",
    "\n",
    "        # L2 regularization\n",
    "        l2_reg = sum(torch.norm(p, 2) ** 2 for p in self.model.parameters() if p.requires_grad)\n",
    "\n",
    "        loss = self.alpha1 * (L_recon + L_pred) + L_lin + self.alpha2 * L_inf + self.alpha3 * l2_reg\n",
    "        return loss, L_recon, L_pred, L_lin, L_inf\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X = batch[0]  # [B, T, V]\n",
    "        loss, L_recon, L_pred, L_lin, L_inf = self.compute_loss(X)\n",
    "        self.log_dict({\n",
    "            'train_loss': loss,\n",
    "            'train_L_recon': L_recon,\n",
    "            'train_L_pred': L_pred,\n",
    "            'train_L_lin': L_lin,\n",
    "            'train_L_inf': L_inf\n",
    "        }, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X = batch[0]\n",
    "        _, _, L_pred, _, _ = self.compute_loss(X)\n",
    "        self.validation_outputs.append(L_pred)\n",
    "        self.log('val_loss', L_pred)\n",
    "        return L_pred\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X = batch[0]\n",
    "        _, _, L_pred, _, _ = self.compute_loss(X)\n",
    "        self.log(\"test_loss\", L_pred)\n",
    "        return L_pred\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        if self.trainer.is_global_zero:\n",
    "            if os.path.exists(\"loss_log.txt\"):\n",
    "                os.remove(\"loss_log.txt\")\n",
    "            if os.path.exists(self.path):\n",
    "                os.remove(self.path)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.is_global_zero:\n",
    "            avg_train_loss = self.trainer.callback_metrics.get(\"train_loss\")\n",
    "            if avg_train_loss is not None:\n",
    "                self.train_losses.append(avg_train_loss.item())\n",
    "                print(f\"Epoch {self.current_epoch}: Average Training Loss = {avg_train_loss.item()}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_outputs).mean()\n",
    "        self.log('avg_val_loss', avg_val_loss)\n",
    "        self.validation_outputs.clear()\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        with open(\"loss_log.txt\", \"a\") as f:\n",
    "            f.write(f\"{avg_val_loss.item()}\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-8, weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.92)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\"\n",
    "            },\n",
    "            \"gradient_clip_val\": 1.0,\n",
    "            \"gradient_clip_algorithm\": \"norm\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 3 \n",
    "hidden_dim = 10  \n",
    "input_dim = 0\n",
    "num_visible = 2\n",
    "num_hidden = 1\n",
    "hidden_size = 32\n",
    "kernel_size = 31\n",
    "n_blocks = 3\n",
    "n_layers = 10\n",
    "n_feature = 2\n",
    "num_real = 3\n",
    "num_complex = 1\n",
    "rank = 3\n",
    "batch_size = 512\n",
    "n_train = 10000\n",
    "n_valid = 1000\n",
    "n_test = 1000\n",
    "dropout = 0\n",
    "num_epochs = 20\n",
    "lamb = 0\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be9de01-836e-4afa-b1f8-09abfbaa6f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('KO_train.csv', header=None)\n",
    "X_valid = pd.read_csv('KO_valid.csv', header=None)\n",
    "X_test = pd.read_csv('KO_test.csv', header=None)\n",
    "X_result = np.concatenate([X_train, X_test, X_valid], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e79be-eb36-4c14-a0d3-c56e65a8671a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "idx_list = [[0, 1], [0, 2], [1, 2]]\n",
    "for idx in idx_list:\n",
    "    X_v_train = X_train.values[idx, :].reshape(2, -1)\n",
    "    X_v_valid = X_valid.values[idx, :].reshape(2, -1)\n",
    "    X_v_test = X_test.values[idx, :].reshape(2, -1)\n",
    "    length = X_train.shape[1] // n_train\n",
    "    H_train = []\n",
    "    for i in range(n_train):\n",
    "        H_train.append(X_v_train[:, i*length:(i+1)*length])\n",
    "    H_train = np.stack([H_train[idx].T for idx in range(n_train)], axis=0)\n",
    "    H_valid = []\n",
    "    for i in range(n_valid):\n",
    "        H_valid.append(X_v_valid[:, i*length:(i+1)*length])\n",
    "    H_valid = np.stack([H_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "    train_dataset = TensorDataset(torch.tensor(H_train, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    valid_dataset = TensorDataset(torch.tensor(H_valid, dtype=torch.float32))\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=99999, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    full_dims = set(range(dim)) \n",
    "    missing_dim = list(full_dims - set(idx))[0]\n",
    "    path = f\"model_checkpoint_hidden_{missing_dim}_deepkoopman\"\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"avg_val_loss\",   \n",
    "        dirpath=\"./\",\n",
    "        filename=path, \n",
    "        save_top_k=1,  \n",
    "        mode=\"min\",   \n",
    "    )\n",
    "    model = DeepKoopman(\n",
    "        input_dim=num_visible + num_hidden,\n",
    "        hidden_dim=hidden_dim,\n",
    "        n_layers=n_layers,\n",
    "        num_real=num_real,\n",
    "        num_complex=num_complex,\n",
    "        visible_dim=num_visible,\n",
    "        kernel_size=kernel_size,\n",
    "        num_hidden=num_hidden\n",
    "    )\n",
    "    lightning_model = TrainModel(model=model, learning_rate=learning_rate, path=path)\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", devices=1, strategy=\"ddp_notebook\", max_epochs=num_epochs, callbacks=[checkpoint_callback])\n",
    "    trainer.fit(lightning_model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8abde0b2-c523-4bad-830f-ae0a236d0f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(num_visible, num_hidden, hidden_size, kernel_size)\n",
    "inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(encoder=encoder, inn_model=inn_model, input_dim=dim, visible_dim=num_visible, lifted_dim=n_feature, Xmax=Xmax, Xmin=Xmin)\n",
    "path = \"model_checkpoint_hidden_2.ckpt\"\n",
    "lightning_model = TrainModel.load_from_checkpoint(path, model=model, rank=rank, learning_rate=learning_rate, map_location=\"cpu\")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)\n",
    "# trainer = pl.Trainer(strategy=\"ddp_notebook\", max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54364185-0c2f-433c-9277-17d4419aa82b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_v_test = X_test.values[[0, 1], :].reshape(2, -1)\n",
    "length = X_v_test.shape[1] // n_test\n",
    "H_test = []\n",
    "for i in range(n_test):\n",
    "    H_test.append(X_v_test[:, i*length:(i+1)*length])\n",
    "H_test = np.stack([H_test[idx].T for idx in range(n_test)], axis=0)\n",
    "test_dataset = TensorDataset(torch.tensor(H_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=9999, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65bcc7-4cda-4e60-8fe3-8b08b994f587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.test(lightning_model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
