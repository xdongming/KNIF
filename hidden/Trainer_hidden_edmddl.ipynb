{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:07:43.368212: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-26 03:07:43.387858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-26 03:07:43.413973: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-26 03:07:43.420642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-26 03:07:43.438678: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "from koopmanlib.dictionary import PsiNNWithEncoder\n",
    "from koopmanlib.solver import KoopmanDLSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 3 \n",
    "hidden_dim = 10  \n",
    "input_dim = 0\n",
    "num_visible = 2\n",
    "num_hidden = 1\n",
    "hidden_size = 32\n",
    "kernel_size = 31\n",
    "n_blocks = 3\n",
    "n_layers = 1\n",
    "n_feature = 2\n",
    "rank = 3\n",
    "batch_size = 512\n",
    "n_train = 10000\n",
    "n_valid = 1000\n",
    "n_test = 1000\n",
    "dropout = 0\n",
    "num_epochs = 20\n",
    "lamb = 0\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be9de01-836e-4afa-b1f8-09abfbaa6f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('KO_train.csv', header=None)\n",
    "X_valid = pd.read_csv('KO_valid.csv', header=None)\n",
    "X_test = pd.read_csv('KO_test.csv', header=None)\n",
    "X_result = np.concatenate([X_train, X_test, X_valid], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190e79be-eb36-4c14-a0d3-c56e65a8671a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-26 03:13:04.861994: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1756177984.877721    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177984.902606    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177984.903910    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177984.908250    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177984.916549    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177984.932465    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177985.024473    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177985.024912    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177985.025555    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177985.026185    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177985.027233    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1756177985.027542    2322 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'psi_nn_layer_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756177987.600574    3979 service.cc:146] XLA service 0x7ef83000e0c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1756177987.600610    3979 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-08-26 03:13:07.688103: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.8398e-06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756177990.479999    3979 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - loss: 5.6820e-06 - val_loss: 4.0603e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8589e-06 - val_loss: 3.4227e-06\n",
      "number of the outer loop: 0\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 3.0824e-06 - val_loss: 2.3663e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.0468e-06 - val_loss: 1.8325e-06\n",
      "number of the outer loop: 1\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5423e-06 - val_loss: 1.5814e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4591e-06 - val_loss: 1.5504e-06\n",
      "number of the outer loop: 2\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4222e-06 - val_loss: 1.4352e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.3740e-06 - val_loss: 1.3916e-06\n",
      "number of the outer loop: 3\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2342e-06 - val_loss: 1.3035e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.2386e-06 - val_loss: 1.3250e-06\n",
      "number of the outer loop: 4\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2267e-06 - val_loss: 1.2131e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1660e-06 - val_loss: 1.1578e-06\n",
      "number of the outer loop: 5\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.1141e-06 - val_loss: 1.3891e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1606e-06 - val_loss: 1.0532e-06\n",
      "number of the outer loop: 6\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1156e-06 - val_loss: 1.1415e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0425e-06 - val_loss: 9.6889e-07\n",
      "number of the outer loop: 7\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.2754e-07 - val_loss: 9.2439e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.3490e-07 - val_loss: 8.7469e-07\n",
      "number of the outer loop: 8\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.0572e-07 - val_loss: 8.8145e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.1151e-07 - val_loss: 7.9791e-07\n",
      "number of the outer loop: 9\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.0131e-07 - val_loss: 7.6499e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.3850e-07 - val_loss: 7.8266e-07\n",
      "number of the outer loop: 10\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.8363e-07 - val_loss: 1.6219e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.1024e-06 - val_loss: 1.1522e-06\n",
      "number of the outer loop: 11\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0702e-06 - val_loss: 7.0768e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.7219e-07 - val_loss: 7.3444e-07\n",
      "number of the outer loop: 12\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3580e-07 - val_loss: 7.5321e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.0584e-07 - val_loss: 9.6270e-07\n",
      "number of the outer loop: 13\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.2175e-07 - val_loss: 6.7065e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.6829e-07 - val_loss: 6.9576e-07\n",
      "number of the outer loop: 14\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3181e-07 - val_loss: 7.1932e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3598e-07 - val_loss: 7.6754e-07\n",
      "number of the outer loop: 15\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.1833e-07 - val_loss: 6.5093e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3950e-07 - val_loss: 6.3900e-07\n",
      "number of the outer loop: 16\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.6661e-07 - val_loss: 6.5199e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.9472e-07 - val_loss: 7.0657e-07\n",
      "number of the outer loop: 17\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.7805e-07 - val_loss: 6.9539e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.9001e-07 - val_loss: 6.5199e-07\n",
      "number of the outer loop: 18\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.8703e-07 - val_loss: 6.8167e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.3205e-07 - val_loss: 7.9869e-07\n",
      "number of the outer loop: 19\n",
      "Error increased. Decay learning rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'psi_nn_layer_3', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - loss: 3.8016e-05 - val_loss: 1.1736e-05\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.4973e-06 - val_loss: 5.0392e-06\n",
      "number of the outer loop: 0\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.5954e-06 - val_loss: 3.0086e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.7265e-06 - val_loss: 2.5481e-06\n",
      "number of the outer loop: 1\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4582e-06 - val_loss: 2.2354e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.1523e-06 - val_loss: 2.1689e-06\n",
      "number of the outer loop: 2\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.0078e-06 - val_loss: 1.9787e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8810e-06 - val_loss: 1.8348e-06\n",
      "number of the outer loop: 3\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7376e-06 - val_loss: 1.7519e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.6882e-06 - val_loss: 1.6963e-06\n",
      "number of the outer loop: 4\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.6661e-06 - val_loss: 1.6498e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5839e-06 - val_loss: 1.5373e-06\n",
      "number of the outer loop: 5\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5021e-06 - val_loss: 1.4758e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4814e-06 - val_loss: 1.4086e-06\n",
      "number of the outer loop: 6\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 1.4220e-06 - val_loss: 1.4010e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3272e-06 - val_loss: 1.3674e-06\n",
      "number of the outer loop: 7\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3260e-06 - val_loss: 1.3307e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2701e-06 - val_loss: 1.3163e-06\n",
      "number of the outer loop: 8\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2601e-06 - val_loss: 1.3252e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2092e-06 - val_loss: 1.2182e-06\n",
      "number of the outer loop: 9\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2012e-06 - val_loss: 1.2485e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1890e-06 - val_loss: 1.1814e-06\n",
      "number of the outer loop: 10\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0945e-06 - val_loss: 1.1896e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.1883e-06 - val_loss: 1.2305e-06\n",
      "number of the outer loop: 11\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0659e-06 - val_loss: 1.0940e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0613e-06 - val_loss: 1.0495e-06\n",
      "number of the outer loop: 12\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0179e-06 - val_loss: 1.0226e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0168e-06 - val_loss: 1.2098e-06\n",
      "number of the outer loop: 13\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2530e-06 - val_loss: 1.1867e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.0810e-06 - val_loss: 9.9335e-07\n",
      "number of the outer loop: 14\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.9298e-07 - val_loss: 1.2125e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.1079e-06 - val_loss: 9.6265e-07\n",
      "number of the outer loop: 15\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.0870e-07 - val_loss: 9.3852e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.1299e-07 - val_loss: 9.0166e-07\n",
      "number of the outer loop: 16\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 9.1850e-07 - val_loss: 9.1369e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.0195e-07 - val_loss: 8.9011e-07\n",
      "number of the outer loop: 17\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.4484e-07 - val_loss: 8.8602e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.6259e-07 - val_loss: 8.7934e-07\n",
      "number of the outer loop: 18\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.6083e-07 - val_loss: 9.0694e-07\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.9245e-07 - val_loss: 8.5394e-07\n",
      "number of the outer loop: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'psi_nn_layer_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - loss: 1.4797e-05 - val_loss: 1.3601e-05\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1814e-05 - val_loss: 1.2207e-05\n",
      "number of the outer loop: 0\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.9368e-06 - val_loss: 7.7879e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.9337e-06 - val_loss: 6.5730e-06\n",
      "number of the outer loop: 1\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.3390e-06 - val_loss: 4.7433e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.5573e-06 - val_loss: 4.3434e-06\n",
      "number of the outer loop: 2\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6314e-06 - val_loss: 3.2167e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.1939e-06 - val_loss: 3.3288e-06\n",
      "number of the outer loop: 3\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6946e-06 - val_loss: 2.6249e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.8343e-06 - val_loss: 2.5000e-06\n",
      "number of the outer loop: 4\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3454e-06 - val_loss: 2.2926e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2373e-06 - val_loss: 1.9701e-06\n",
      "number of the outer loop: 5\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9892e-06 - val_loss: 2.1423e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.3421e-06 - val_loss: 1.9168e-06\n",
      "number of the outer loop: 6\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.9243e-06 - val_loss: 1.9124e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7703e-06 - val_loss: 1.8523e-06\n",
      "number of the outer loop: 7\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8217e-06 - val_loss: 1.6297e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 1.6077e-06 - val_loss: 1.5433e-06\n",
      "number of the outer loop: 8\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5788e-06 - val_loss: 1.5176e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.5642e-06 - val_loss: 1.5907e-06\n",
      "number of the outer loop: 9\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5335e-06 - val_loss: 1.5399e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5798e-06 - val_loss: 1.5017e-06\n",
      "number of the outer loop: 10\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5196e-06 - val_loss: 1.3945e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4119e-06 - val_loss: 1.4824e-06\n",
      "number of the outer loop: 11\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4506e-06 - val_loss: 1.4495e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3686e-06 - val_loss: 1.3087e-06\n",
      "number of the outer loop: 12\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.3365e-06 - val_loss: 1.2420e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.3729e-06 - val_loss: 1.5938e-06\n",
      "number of the outer loop: 13\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.4406e-06 - val_loss: 1.2849e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 1.2975e-06 - val_loss: 1.2415e-06\n",
      "number of the outer loop: 14\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2417e-06 - val_loss: 1.2036e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2806e-06 - val_loss: 1.3009e-06\n",
      "number of the outer loop: 15\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1704e-06 - val_loss: 1.2183e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2166e-06 - val_loss: 1.1229e-06\n",
      "number of the outer loop: 16\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1627e-06 - val_loss: 1.1229e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2104e-06 - val_loss: 1.3254e-06\n",
      "number of the outer loop: 17\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1872e-06 - val_loss: 1.1137e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2414e-06 - val_loss: 1.1400e-06\n",
      "number of the outer loop: 18\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1003e-06 - val_loss: 1.0388e-06\n",
      "Epoch 2/2\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1653e-06 - val_loss: 1.0692e-06\n",
      "number of the outer loop: 19\n"
     ]
    }
   ],
   "source": [
    "idx_list = [[0, 1], [0, 2], [1, 2]]\n",
    "for idx in idx_list:\n",
    "    error_temp = []\n",
    "    X_v_train = X_train.values[idx, :].reshape(2, -1)\n",
    "    X_v_valid = X_valid.values[idx, :].reshape(2, -1)\n",
    "    X_v_test = X_test.values[idx, :].reshape(2, -1)\n",
    "    length = X_train.shape[1] // n_train\n",
    "    H_train = []\n",
    "    for i in range(n_train):\n",
    "        H_train.append(X_v_train[:, i*length:(i+1)*length])\n",
    "    H_train = np.stack([H_train[idx].T for idx in range(n_train)], axis=0)\n",
    "    H_valid = []\n",
    "    for i in range(n_valid):\n",
    "        H_valid.append(X_v_valid[:, i*length:(i+1)*length])\n",
    "    H_valid = np.stack([H_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "    H_test = []\n",
    "    for i in range(n_test):\n",
    "        H_test.append(X_v_test[:, i*length:(i+1)*length])\n",
    "    H_test = np.stack([H_test[idx].T for idx in range(n_test)], axis=0)\n",
    "    data_train = [H_train[:, 0:-1,:], H_train[:, 1:,:]]\n",
    "    data_valid = [H_valid[:, 0:-1,:], H_valid[:, 1:,:]]\n",
    "    basis_function = PsiNNWithEncoder(\n",
    "        visible_dim=num_visible,           \n",
    "        num_hidden=num_hidden,       \n",
    "        kernel_size=kernel_size,\n",
    "        layer_sizes=[hidden_dim, hidden_dim, hidden_dim],\n",
    "        n_psi_train=dim+n_feature,\n",
    "        target_dim=num_visible\n",
    "    )\n",
    "    solver = KoopmanDLSolver(dic=basis_function,\n",
    "                            target_dim=dim-1,\n",
    "                            reg=0.0)\n",
    "    solver.build(data_train=data_train,\n",
    "                     data_valid=data_valid,\n",
    "                     epochs=num_epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     lr=learning_rate,\n",
    "                     log_interval=1,\n",
    "                     lr_decay_factor=0.92)\n",
    "    for j in range(n_test):\n",
    "        x_traj = H_test[j, :,:]\n",
    "        x0_test = x_traj[0]\n",
    "        x0_test = x0_test.reshape(-1, x0_test.shape[-1])\n",
    "        x_est_traj_DL = solver.predict(x0_test, length-1)\n",
    "        error_temp.append((x_est_traj_DL[:, :dim]-x_traj[1:, :dim]) ** 2)\n",
    "    error = np.mean(np.array(error_temp))\n",
    "    full_dims = set(range(dim)) \n",
    "    missing_dim = list(full_dims - set(idx))[0]\n",
    "    path = f\"error_hidden_{missing_dim}_edmddl.csv\"\n",
    "    df = pd.DataFrame([error])\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03dc3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
