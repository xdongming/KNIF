{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 08:31:22.226813: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-09 08:31:22.242435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-09 08:31:22.260205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-09 08:31:22.265413: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-09 08:31:22.278650: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.compat.v1 as tf\n",
    "from koopmanlib.dictionary import PsiNN\n",
    "from koopmanlib.solver import KoopmanDLSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 6\n",
    "hidden_dim = 80\n",
    "input_dim = 6\n",
    "n_feature = 14\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "n_train = 6660\n",
    "n_test = 606\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5c67d8-35ba-439c-a7ca-a6c388c65c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('robot_X_train.csv', header=None).values\n",
    "X_test = pd.read_csv('robot_X_test.csv', header=None).values\n",
    "U_train = pd.read_csv('robot_U_train.csv', header=None).values\n",
    "U_test = pd.read_csv('robot_U_test.csv', header=None).values\n",
    "\n",
    "length = X_train.shape[1] // n_train\n",
    "HX_train = []\n",
    "HU_train = []\n",
    "for i in range(n_train):\n",
    "    HX_train.append(X_train[:, i*length:(i+1)*length])\n",
    "    HU_train.append(U_train[:, i*length:(i+1)*length])\n",
    "HX_train = np.stack([HX_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HU_train = np.stack([HU_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HX_test = []\n",
    "HU_test = []\n",
    "for i in range(n_test):\n",
    "    HX_test.append(X_test[:, i*length:(i+1)*length])\n",
    "    HU_test.append(U_test[:, i*length:(i+1)*length])\n",
    "HX_test = np.stack([HX_test[idx].T for idx in range(n_test)], axis=0)\n",
    "HU_test = np.stack([HU_test[idx].T for idx in range(n_test)], axis=0)\n",
    "\n",
    "H_train = np.concatenate([HX_train, HU_train], axis=-1)\n",
    "H_test = np.concatenate([HX_test, HU_test], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31b4457-3c72-40df-b3ee-036020940634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'psi_nn_layer_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749457920.366451     977 service.cc:146] XLA service 0x7fc510005320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1749457920.366487     977 service.cc:154]   StreamExecutor device (0): NVIDIA H100 80GB HBM3, Compute Capability 9.0\n",
      "2025-06-09 08:32:00.396576: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-09 08:32:00.728659: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m212/521\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.2286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749457921.231618     977 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.2038 - val_loss: 0.1481\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1443 - val_loss: 0.1321\n",
      "number of the outer loop: 0\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1083 - val_loss: 0.1015\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0995 - val_loss: 0.0929\n",
      "number of the outer loop: 1\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0883 - val_loss: 0.0809\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0820 - val_loss: 0.0800\n",
      "number of the outer loop: 2\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0775 - val_loss: 0.0752\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0730 - val_loss: 0.0694\n",
      "number of the outer loop: 3\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0696 - val_loss: 0.0641\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0655 - val_loss: 0.0642\n",
      "number of the outer loop: 4\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0632 - val_loss: 0.0626\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0617 - val_loss: 0.0639\n",
      "number of the outer loop: 5\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0585 - val_loss: 0.0562\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0565 - val_loss: 0.0569\n",
      "number of the outer loop: 6\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0547 - val_loss: 0.0573\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0541 - val_loss: 0.0499\n",
      "number of the outer loop: 7\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0523 - val_loss: 0.0502\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0500 - val_loss: 0.0484\n",
      "number of the outer loop: 8\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0490 - val_loss: 0.0468\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0477 - val_loss: 0.0477\n",
      "number of the outer loop: 9\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0465 - val_loss: 0.0456\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0451 - val_loss: 0.0451\n",
      "number of the outer loop: 10\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0447 - val_loss: 0.0428\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0443 - val_loss: 0.0417\n",
      "number of the outer loop: 11\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0425 - val_loss: 0.0419\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0416 - val_loss: 0.0408\n",
      "number of the outer loop: 12\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0413 - val_loss: 0.0398\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0405 - val_loss: 0.0387\n",
      "number of the outer loop: 13\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0393 - val_loss: 0.0379\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0385 - val_loss: 0.0397\n",
      "number of the outer loop: 14\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0374 - val_loss: 0.0359\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0370 - val_loss: 0.0347\n",
      "number of the outer loop: 15\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0365 - val_loss: 0.0352\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0355 - val_loss: 0.0343\n",
      "number of the outer loop: 16\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0354 - val_loss: 0.0349\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0344 - val_loss: 0.0330\n",
      "number of the outer loop: 17\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0342 - val_loss: 0.0384\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0347 - val_loss: 0.0330\n",
      "number of the outer loop: 18\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0331 - val_loss: 0.0345\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0330 - val_loss: 0.0377\n",
      "number of the outer loop: 19\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0324 - val_loss: 0.0316\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0313 - val_loss: 0.0299\n",
      "number of the outer loop: 20\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0303 - val_loss: 0.0305\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0310 - val_loss: 0.0319\n",
      "number of the outer loop: 21\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0310 - val_loss: 0.0299\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0307 - val_loss: 0.0292\n",
      "number of the outer loop: 22\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0295 - val_loss: 0.0293\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0298 - val_loss: 0.0290\n",
      "number of the outer loop: 23\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0290 - val_loss: 0.0298\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0288 - val_loss: 0.0282\n",
      "number of the outer loop: 24\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0287 - val_loss: 0.0282\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0291 - val_loss: 0.0263\n",
      "number of the outer loop: 25\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0284 - val_loss: 0.0273\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0280 - val_loss: 0.0306\n",
      "number of the outer loop: 26\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0277 - val_loss: 0.0290\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0276 - val_loss: 0.0269\n",
      "number of the outer loop: 27\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0267 - val_loss: 0.0273\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0268 - val_loss: 0.0262\n",
      "number of the outer loop: 28\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0265 - val_loss: 0.0252\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0260 - val_loss: 0.0267\n",
      "number of the outer loop: 29\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0262 - val_loss: 0.0274\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0267 - val_loss: 0.0267\n",
      "number of the outer loop: 30\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0259 - val_loss: 0.0246\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0256 - val_loss: 0.0261\n",
      "number of the outer loop: 31\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0259 - val_loss: 0.0267\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0256 - val_loss: 0.0238\n",
      "number of the outer loop: 32\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0247 - val_loss: 0.0259\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0254 - val_loss: 0.0239\n",
      "number of the outer loop: 33\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0242 - val_loss: 0.0229\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0237 - val_loss: 0.0240\n",
      "number of the outer loop: 34\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0234 - val_loss: 0.0237\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0239 - val_loss: 0.0228\n",
      "number of the outer loop: 35\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0228 - val_loss: 0.0230\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0228 - val_loss: 0.0237\n",
      "number of the outer loop: 36\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0225 - val_loss: 0.0220\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0227 - val_loss: 0.0215\n",
      "number of the outer loop: 37\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0222 - val_loss: 0.0234\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0224 - val_loss: 0.0226\n",
      "number of the outer loop: 38\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0225 - val_loss: 0.0223\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0218 - val_loss: 0.0220\n",
      "number of the outer loop: 39\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0226 - val_loss: 0.0229\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0223 - val_loss: 0.0222\n",
      "number of the outer loop: 40\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0207 - val_loss: 0.0212\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0216 - val_loss: 0.0211\n",
      "number of the outer loop: 41\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0210 - val_loss: 0.0201\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "number of the outer loop: 42\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0211 - val_loss: 0.0206\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0209 - val_loss: 0.0201\n",
      "number of the outer loop: 43\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0205 - val_loss: 0.0197\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0206 - val_loss: 0.0215\n",
      "number of the outer loop: 44\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0206 - val_loss: 0.0203\n",
      "number of the outer loop: 45\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0201 - val_loss: 0.0196\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0197 - val_loss: 0.0200\n",
      "number of the outer loop: 46\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0199 - val_loss: 0.0198\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0202 - val_loss: 0.0205\n",
      "number of the outer loop: 47\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0192 - val_loss: 0.0190\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "number of the outer loop: 48\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0193 - val_loss: 0.0192\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0190 - val_loss: 0.0188\n",
      "number of the outer loop: 49\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0199\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0189 - val_loss: 0.0183\n",
      "number of the outer loop: 50\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0180\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 0.0190\n",
      "number of the outer loop: 51\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0182 - val_loss: 0.0186\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "number of the outer loop: 52\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0181 - val_loss: 0.0185\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0181 - val_loss: 0.0177\n",
      "number of the outer loop: 53\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0182 - val_loss: 0.0184\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0180 - val_loss: 0.0187\n",
      "number of the outer loop: 54\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0177 - val_loss: 0.0186\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0177 - val_loss: 0.0175\n",
      "number of the outer loop: 55\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "number of the outer loop: 56\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0174 - val_loss: 0.0180\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0177 - val_loss: 0.0172\n",
      "number of the outer loop: 57\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0178 - val_loss: 0.0176\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0175 - val_loss: 0.0166\n",
      "number of the outer loop: 58\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0173 - val_loss: 0.0174\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0169\n",
      "number of the outer loop: 59\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0173 - val_loss: 0.0169\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0172 - val_loss: 0.0171\n",
      "number of the outer loop: 60\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0170 - val_loss: 0.0172\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0170 - val_loss: 0.0165\n",
      "number of the outer loop: 61\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0171\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0174\n",
      "number of the outer loop: 62\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0170 - val_loss: 0.0190\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0173 - val_loss: 0.0166\n",
      "number of the outer loop: 63\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0165 - val_loss: 0.0163\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0164 - val_loss: 0.0166\n",
      "number of the outer loop: 64\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0167 - val_loss: 0.0161\n",
      "number of the outer loop: 65\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0162 - val_loss: 0.0159\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0163 - val_loss: 0.0161\n",
      "number of the outer loop: 66\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0161 - val_loss: 0.0162\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0162 - val_loss: 0.0169\n",
      "number of the outer loop: 67\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0160 - val_loss: 0.0157\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0156\n",
      "number of the outer loop: 68\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0158\n",
      "number of the outer loop: 69\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0156\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0157\n",
      "number of the outer loop: 70\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0157\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0157 - val_loss: 0.0157\n",
      "number of the outer loop: 71\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0155 - val_loss: 0.0154\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0155 - val_loss: 0.0149\n",
      "number of the outer loop: 72\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0154 - val_loss: 0.0153\n",
      "number of the outer loop: 73\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0155 - val_loss: 0.0150\n",
      "number of the outer loop: 74\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0154 - val_loss: 0.0152\n",
      "number of the outer loop: 75\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0150 - val_loss: 0.0151\n",
      "number of the outer loop: 76\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0152 - val_loss: 0.0149\n",
      "number of the outer loop: 77\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0147 - val_loss: 0.0145\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0148 - val_loss: 0.0147\n",
      "number of the outer loop: 78\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0148 - val_loss: 0.0145\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 0.0148\n",
      "number of the outer loop: 79\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0147 - val_loss: 0.0146\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 0.0144\n",
      "number of the outer loop: 80\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0147 - val_loss: 0.0145\n",
      "number of the outer loop: 81\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0145 - val_loss: 0.0148\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0147\n",
      "number of the outer loop: 82\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0145 - val_loss: 0.0142\n",
      "number of the outer loop: 83\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0145\n",
      "number of the outer loop: 84\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "number of the outer loop: 85\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "number of the outer loop: 86\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "number of the outer loop: 87\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0139 - val_loss: 0.0138\n",
      "number of the outer loop: 88\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0140 - val_loss: 0.0137\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "number of the outer loop: 89\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0140 - val_loss: 0.0137\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0139 - val_loss: 0.0139\n",
      "number of the outer loop: 90\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0138 - val_loss: 0.0133\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0138 - val_loss: 0.0137\n",
      "number of the outer loop: 91\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0135\n",
      "number of the outer loop: 92\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0138\n",
      "number of the outer loop: 93\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0136 - val_loss: 0.0133\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0138\n",
      "number of the outer loop: 94\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0135 - val_loss: 0.0137\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0139\n",
      "number of the outer loop: 95\n",
      "Error increased. Decay learning rate\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0135 - val_loss: 0.0134\n",
      "number of the outer loop: 96\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0135 - val_loss: 0.0133\n",
      "number of the outer loop: 97\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0132 - val_loss: 0.0133\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0133\n",
      "number of the outer loop: 98\n",
      "Epoch 1/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 2/2\n",
      "\u001b[1m521/521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0132 - val_loss: 0.0133\n",
      "number of the outer loop: 99\n"
     ]
    }
   ],
   "source": [
    "error_temp = []\n",
    "\n",
    "data_train = [H_train[:, 0:5,:].reshape(-1, dim+input_dim), H_train[:, 1:6,:].reshape(-1, dim+input_dim)]\n",
    "data_valid = [H_train[:, 0:5,:].reshape(-1, dim+input_dim), H_train[:, 1:6,:].reshape(-1, dim+input_dim)]\n",
    "basis_function = PsiNN(layer_sizes=[hidden_dim, hidden_dim, hidden_dim], n_psi_train=dim+n_feature)\n",
    "solver = KoopmanDLSolver(dic=basis_function,\n",
    "                        target_dim=dim+input_dim,\n",
    "                        reg=0.0)\n",
    "solver.build(data_train=data_train,\n",
    "                 data_valid=data_valid,\n",
    "                 epochs=num_epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 lr=learning_rate,\n",
    "                 log_interval=1,\n",
    "                 lr_decay_factor=0.92)\n",
    "for j in range(n_test):\n",
    "    x_traj = H_test[j, 0:6,:]\n",
    "    x0_test = x_traj[0]\n",
    "    x0_test = x0_test.reshape(-1, x0_test.shape[-1])\n",
    "    x_est_traj_DL = solver.predict(x0_test, 5)\n",
    "    error_temp.append((x_est_traj_DL[:, :dim]-x_traj[1:, :dim]) ** 2)\n",
    "error = np.mean(np.array(error_temp))\n",
    "    \n",
    "df = pd.DataFrame([error])\n",
    "df.to_csv(\"Robot_EDMDDL.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
