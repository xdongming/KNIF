{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import math\n",
    "from pydmd import DMD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualFlow(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_layers, input_dim=0, dropout=0, LDJ=False, block_id=0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_dim = input_dim\n",
    "        self.LDJ = LDJ\n",
    "        self.block_id = block_id\n",
    "\n",
    "        flip = (block_id % 2 == 0)\n",
    "        self.flow = Flow(dim, hidden_dim, flip=flip)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        x_e = x\n",
    "        if not reverse:\n",
    "            y = self.flow(x_e, reverse=False)\n",
    "            logdet = 0\n",
    "            return y, logdet\n",
    "        else:\n",
    "            y = self.flow(x_e, reverse=True)\n",
    "            return y\n",
    "\n",
    "class Flow(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_dim, flip=False):\n",
    "        super().__init__()\n",
    "        self.coupling = AffineCoupling(in_channel, hidden_dim, flip)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        return self.coupling(x, reverse)\n",
    "\n",
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, flip=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.flip = flip\n",
    "\n",
    "        self.split_idx = dim // 2\n",
    "        self.rest_dim = dim - self.split_idx\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.split_idx, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.rest_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        if self.flip:\n",
    "            x2, x1 = torch.split(x, [self.rest_dim, self.split_idx], dim=-1)\n",
    "        else:\n",
    "            x1, x2 = torch.split(x, [self.split_idx, self.rest_dim], dim=-1)\n",
    "\n",
    "        h = self.net(x1)\n",
    "        s, t = torch.chunk(h, 2, dim=-1)\n",
    "        s = torch.tanh(s)\n",
    "\n",
    "        if not reverse:\n",
    "            y2 = x2 * torch.exp(s) + t\n",
    "        else:\n",
    "            y2 = (x2 - t) * torch.exp(-s)\n",
    "\n",
    "        if self.flip:\n",
    "            return torch.cat([y2, x1], dim=-1)\n",
    "        else:\n",
    "            return torch.cat([x1, y2], dim=-1)\n",
    "    \n",
    "class InvertibleNN(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_blocks, n_layers, input_dim=0, dropout=0, LDJ=False):\n",
    "        super(InvertibleNN, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        self.blocks = nn.ModuleList([ResidualFlow(self.dim, self.hidden_dim, self.n_layers, self.input_dim, dropout, LDJ, block_id=i) for i in range(self.n_blocks)])\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        if not reverse:\n",
    "            ldj_total = 0\n",
    "            for block in self.blocks:\n",
    "                x, ldj = block(x, reverse)\n",
    "                ldj_total += ldj\n",
    "            return x, ldj_total\n",
    "        else:\n",
    "            for block in reversed(self.blocks):\n",
    "                x = block(x, reverse)\n",
    "            return x\n",
    "    \n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, inn_model, input_dim, lifted_dim):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.inn_model = inn_model  \n",
    "        self.lifted_dim = lifted_dim\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        x = x.float()\n",
    "        if not reverse:\n",
    "            zero_pad = torch.zeros(x.shape[0], x.shape[1], self.lifted_dim, device=x.device)\n",
    "            x = torch.cat((x, zero_pad), dim=-1)\n",
    "            x, ldj = self.inn_model(x, u, reverse)\n",
    "            return x, ldj\n",
    "        else:\n",
    "            x = self.inn_model(x, u, reverse)\n",
    "            x = x[:, :self.input_dim]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f82eb2-731c-4827-9194-6a65f9842548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dmd(model, X, rank):\n",
    "    GX_pred_list = []\n",
    "    GX_list = []\n",
    "    X_list = []\n",
    "    GX, _ = model(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        GX_temp = GX[i, :, :].T\n",
    "        dmd = DMD(svd_rank=rank, exact=True, sorted_eigs='abs')\n",
    "        dmd.fit(GX_temp.cpu().detach().numpy())\n",
    "        GX_pred = dmd.reconstructed_data.real\n",
    "        GX_pred = np.array(GX_pred, dtype=np.float32)\n",
    "        GX_pred = torch.from_numpy(GX_pred).cuda()\n",
    "        GX_pred_list.append(GX_pred)\n",
    "        GX_list.append(GX_temp)\n",
    "        X_list.append(X[i, :, :].T)\n",
    "    GX_pred = torch.cat(GX_pred_list, dim=-1)\n",
    "    GX = torch.cat(GX_list, dim=1)\n",
    "    X = torch.cat(X_list, dim=-1)\n",
    "\n",
    "    return GX, GX_pred, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43d5609-1fb3-4f6c-a55b-23216203377a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "    def __init__(self, model, rank, learning_rate=1e-3, lamb=1, path=\"model_checkpoint_NP\"):\n",
    "        super(TrainModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.best_val_loss = float('inf') \n",
    "        self.validation_outputs = []\n",
    "        self.lamb = lamb\n",
    "        self.train_losses = []\n",
    "        self.rank = rank\n",
    "        self.path = path+'.ckpt'\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch = batch[0]\n",
    "        GY, GY_pred, Y = dmd(self.model, X_batch, self.rank)\n",
    "        Y_pred = self.model(GY_pred.T, reverse=True)\n",
    "        loss_lin = self.criterion(GY, GY_pred)\n",
    "        loss_recons = self.criterion(Y.T, Y_pred)\n",
    "\n",
    "        loss = loss_lin + self.lamb * loss_recons\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, Z = dmd(self.model, Z_batch, self.rank)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        valid_loss = self.criterion(Z_pred, Z.T)\n",
    "\n",
    "        self.validation_outputs.append(valid_loss)\n",
    "        self.log('val_loss', valid_loss)\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, Z = dmd(self.model, Z_batch, self.rank)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        test_loss = self.criterion(Z_pred[:, :self.model.inn_model.input_dim], Z.T[:, :self.model.inn_model.input_dim])\n",
    "\n",
    "        self.log('test_loss', test_loss)\n",
    "        return test_loss\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        if self.trainer.is_global_zero: \n",
    "            if os.path.exists(\"loss_log.txt\"):\n",
    "                os.remove(\"loss_log.txt\")\n",
    "            if os.path.exists(self.path):\n",
    "                os.remove(self.path)\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.is_global_zero:\n",
    "            avg_train_loss = self.trainer.callback_metrics.get(\"train_loss\")\n",
    "            if avg_train_loss is not None:\n",
    "                self.train_losses.append(avg_train_loss.item()) \n",
    "                print(f\"Epoch {self.current_epoch}: Average Training Loss = {avg_train_loss.item()}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_outputs).mean()  \n",
    "        self.log('avg_val_loss', avg_val_loss)\n",
    "        self.validation_outputs.clear()\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        with open(\"loss_log.txt\", \"a\") as f:\n",
    "            f.write(f\"{avg_val_loss.item()}\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-08,\n",
    "                                            weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=1,\n",
    "            gamma=0.99\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",  \n",
    "            },\n",
    "            \"gradient_clip_val\": 1.0, \n",
    "            \"gradient_clip_algorithm\": \"norm\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd91c08d-d518-4473-85da-d92ab90d7dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 2\n",
    "hidden_dim = 20 \n",
    "input_dim = 1\n",
    "n_blocks = 3  \n",
    "n_layers = 1\n",
    "n_feature = 8\n",
    "rank = 5\n",
    "batch_size = 512\n",
    "n_train = 10000\n",
    "n_valid = 1000\n",
    "n_test = 1000\n",
    "dropout = 0\n",
    "num_epochs = 100 \n",
    "lamb = 0\n",
    "learning_rate = 1e-3  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b85bfb-a714-4750-9b83-03efae756757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('Non_X_train.csv', header=None).values\n",
    "X_valid = pd.read_csv('Non_X_valid.csv', header=None).values\n",
    "X_test = pd.read_csv('Non_X_test.csv', header=None).values\n",
    "U_train = pd.read_csv('Non_U_train.csv', header=None).values\n",
    "U_valid = pd.read_csv('Non_U_valid.csv', header=None).values\n",
    "U_test = pd.read_csv('Non_U_test.csv', header=None).values\n",
    "\n",
    "length = X_train.shape[1] // n_train\n",
    "HX_train = []\n",
    "HU_train = []\n",
    "for i in range(n_train):\n",
    "    HX_train.append(X_train[:, i*length:(i+1)*length])\n",
    "    HU_train.append(U_train[:, i*length:(i+1)*length])\n",
    "HX_train = np.stack([HX_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HU_train = np.stack([HU_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HX_valid = []\n",
    "HU_valid = []\n",
    "for i in range(n_valid):\n",
    "    HX_valid.append(X_valid[:, i*length:(i+1)*length])\n",
    "    HU_valid.append(U_valid[:, i*length:(i+1)*length])\n",
    "HX_valid = np.stack([HX_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "HU_valid = np.stack([HU_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "H_train = np.concatenate([HX_train, HU_train], axis=-1)\n",
    "H_valid = np.concatenate([HX_valid, HU_valid], axis=-1)\n",
    "train_dataset = TensorDataset(torch.tensor(H_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_dataset = TensorDataset(torch.tensor(H_valid, dtype=torch.float32))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=99999, shuffle=True, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4675e66-c408-4de1-8c1e-5d792e4e1a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "path = \"model_checkpoint_NP_flowdmd\"\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"avg_val_loss\",   \n",
    "    dirpath=\"./\", \n",
    "    filename=path, \n",
    "    save_top_k=1, \n",
    "    mode=\"min\",    \n",
    ")\n",
    "inn_model = InvertibleNN(dim=dim+input_dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim+input_dim, lifted_dim=n_feature)\n",
    "lightning_model = TrainModel(model=model, rank=rank, learning_rate=learning_rate, lamb=lamb, path=path)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs, callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1118f8d8-8d86-40c3-a525-4593ef2a3a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "inn_model = InvertibleNN(dim=dim+input_dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature)\n",
    "path = \"model_checkpoint_NP_flowdmd.ckpt\"\n",
    "lightning_model = TrainModel.load_from_checkpoint(path, model=model, rank=rank, learning_rate=learning_rate, map_location=\"cpu\")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ccadc5-80ce-4acd-afd0-b27a468b6a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "length = X_test.shape[1] // n_test\n",
    "HX_test = []\n",
    "HU_test = []\n",
    "for i in range(n_test):\n",
    "    HX_test.append(X_test[:, i*length:(i+1)*length])\n",
    "    HU_test.append(U_test[:, i*length:(i+1)*length])\n",
    "HX_test = np.stack([HX_test[idx].T for idx in range(n_test)], axis=0)\n",
    "HU_test = np.stack([HU_test[idx].T for idx in range(n_test)], axis=0)\n",
    "H_test = np.concatenate([HX_test, HU_test], axis=-1)\n",
    "test_dataset = TensorDataset(torch.tensor(H_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=9999, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae25f43-ccee-4521-83f8-55f1586370fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.0030282342340797186\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0030282342340797186}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.test(lightning_model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
