{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import math\n",
    "from pydmd import DMD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from torchdiffeq import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a57628-6d4f-47de-842f-e5d20fae90a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_layers, input_dim=0, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.use_control = input_dim > 0\n",
    "\n",
    "        in_dim = dim + input_dim if self.use_control else dim\n",
    "        layers = [nn.Linear(in_dim, hidden_dim), nn.Tanh()]\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers.append(nn.Linear(hidden_dim, dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, t, x, u=None):\n",
    "        if self.use_control:\n",
    "            if u is None:\n",
    "                raise ValueError(\"Control input u must be provided.\")\n",
    "            x_input = torch.cat([x, u], dim=-1)\n",
    "        else:\n",
    "            x_input = x\n",
    "        return self.net(x_input)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, odefunc, t=torch.tensor([0.0, 1.0]), solver='rk4'):\n",
    "        super().__init__()\n",
    "        self.odefunc = odefunc\n",
    "        self.integration_time = t\n",
    "        self.solver = solver\n",
    "\n",
    "    def forward(self, x, u=None):\n",
    "        t = self.integration_time.to(x.device)\n",
    "\n",
    "        if self.odefunc.use_control:\n",
    "            if u is None:\n",
    "                raise ValueError(\"This NeuralODE expects control input u, but got None.\")\n",
    "            out = odeint(lambda t, x_: self.odefunc(t, x_, u), x, t, method=self.solver)\n",
    "        else:\n",
    "            out = odeint(lambda t, x_: self.odefunc(t, x_), x, t, method=self.solver)\n",
    "\n",
    "        return out[-1], 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8996c880-1612-417a-ade9-b294f93ad045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def node_rollout(model, X, U=None):\n",
    "    X_pred_list = []\n",
    "    X_true_list = []\n",
    "\n",
    "    B, T, dim = X.shape\n",
    "\n",
    "    for i in range(B):\n",
    "        Xi = X[i]         # [T, dim]\n",
    "        Xi0 = Xi[:-1]     # [T-1, dim]\n",
    "        Xi1 = Xi[1:]      # [T-1, dim]\n",
    "\n",
    "        if U is not None:\n",
    "            Ui = U[i]\n",
    "            Ui0 = Ui[:-1]\n",
    "\n",
    "        Xi_pred = []\n",
    "        for t in range(T - 1):\n",
    "            xt = Xi0[t:t+1]      # [1, dim]\n",
    "            if U is not None:\n",
    "                ut = Ui0[t:t+1]  # [1, input_dim]\n",
    "                xt_next, _ = model(xt, ut)\n",
    "            else:\n",
    "                xt_next, _ = model(xt)\n",
    "            Xi_pred.append(xt_next)\n",
    "\n",
    "        Xi_pred = torch.cat(Xi_pred, dim=0).T     # [dim, T-1]\n",
    "        Xi_true = Xi1.T                           # [dim, T-1]\n",
    "\n",
    "        X_pred_list.append(Xi_pred)\n",
    "        X_true_list.append(Xi_true)\n",
    "\n",
    "    X_pred_all = torch.cat(X_pred_list, dim=-1)   # [dim, total]\n",
    "    X_true_all = torch.cat(X_true_list, dim=-1)\n",
    "    return X_true_all, X_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bede68be-e48a-4205-b695-7cc047d892cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3, path=\"model_checkpoint_NODE_control\"):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.validation_outputs = []\n",
    "        self.train_losses = []\n",
    "        self.path = path + '.ckpt'\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        return self.model(x, u)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch, U_batch = batch  # [B, T, dim], [B, T, input_dim]\n",
    "        X_true, X_pred = node_rollout(self.model, X_batch, U_batch)\n",
    "\n",
    "        loss = self.criterion(X_true, X_pred)\n",
    "        self.log('train_loss', loss, on_step=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X_batch, U_batch = batch\n",
    "        X_true, X_pred = node_rollout(self.model, X_batch, U_batch)\n",
    "\n",
    "        valid_loss = self.criterion(X_pred, X_true)\n",
    "        self.validation_outputs.append(valid_loss)\n",
    "        self.log('val_loss', valid_loss)\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X_batch, U_batch = batch\n",
    "        X_true, X_pred = node_rollout(self.model, X_batch, U_batch)\n",
    "\n",
    "        test_loss = self.criterion(X_pred, X_true)\n",
    "        self.log('test_loss', test_loss)\n",
    "        return test_loss\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        if self.trainer.is_global_zero:\n",
    "            if os.path.exists(\"loss_log.txt\"):\n",
    "                os.remove(\"loss_log.txt\")\n",
    "            if os.path.exists(self.path):\n",
    "                os.remove(self.path)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_outputs).mean()\n",
    "        self.log('avg_val_loss', avg_val_loss)\n",
    "        self.validation_outputs.clear()\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        with open(\"loss_log.txt\", \"a\") as f:\n",
    "            f.write(f\"{avg_val_loss.item()}\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.92)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "            \"gradient_clip_val\": 1.0,\n",
    "            \"gradient_clip_algorithm\": \"norm\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68eaa78e-ee59-4c38-abb6-18b9ae656e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 2  \n",
    "hidden_dim = 20  \n",
    "input_dim = 1\n",
    "n_blocks = 5  \n",
    "n_layers = 10\n",
    "n_feature = 18\n",
    "rank = 50\n",
    "batch_size = 64\n",
    "batch_size = 512\n",
    "n_train = 10000\n",
    "n_valid = 1000\n",
    "n_test = 1000\n",
    "dropout = 0\n",
    "num_epochs = 100  \n",
    "lamb = 0\n",
    "learning_rate = 1e-3 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6874831a-16e4-4744-8cc9-1cf2c819a392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('limit_X_train.csv', header=None).values\n",
    "X_valid = pd.read_csv('limit_X_valid.csv', header=None).values\n",
    "X_test = pd.read_csv('limit_X_test.csv', header=None).values\n",
    "U_train = pd.read_csv('limit_U_train.csv', header=None).values\n",
    "U_valid = pd.read_csv('limit_U_valid.csv', header=None).values\n",
    "U_test = pd.read_csv('limit_U_test.csv', header=None).values\n",
    "\n",
    "length = X_train.shape[1] // n_train\n",
    "HX_train = []\n",
    "HU_train = []\n",
    "for i in range(n_train):\n",
    "    HX_train.append(X_train[:, i*length:(i+1)*length])\n",
    "    HU_train.append(U_train[:, i*length:(i+1)*length])\n",
    "HX_train = np.stack([HX_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HU_train = np.stack([HU_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HX_valid = []\n",
    "HU_valid = []\n",
    "for i in range(n_valid):\n",
    "    HX_valid.append(X_valid[:, i*length:(i+1)*length])\n",
    "    HU_valid.append(U_valid[:, i*length:(i+1)*length])\n",
    "HX_valid = np.stack([HX_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "HU_valid = np.stack([HU_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "train_dataset = TensorDataset(torch.tensor(HX_train, dtype=torch.float32), torch.tensor(HU_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_dataset = TensorDataset(torch.tensor(HX_valid, dtype=torch.float32), torch.tensor(HU_valid, dtype=torch.float32))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=99999, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18639093-8bd2-44b5-82b7-ad2fabbe46d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"model_checkpoint_limit_node\"\n",
    "odefunc = ODEFunc(dim=dim, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "neural_ode = NeuralODE(odefunc=odefunc, t=torch.tensor([0.0, 1.0]), solver=\"euler\")\n",
    "lightning_model = TrainModel(model=neural_ode, learning_rate=learning_rate, path=model_path)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"avg_val_loss\",\n",
    "    dirpath=\"./\",\n",
    "    filename=model_path,\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, max_epochs=num_epochs, callbacks=[checkpoint_callback])\n",
    "trainer.fit(lightning_model, train_loader, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8abde0b2-c523-4bad-830f-ae0a236d0f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "odefunc = ODEFunc(dim=dim, hidden_dim=hidden_dim, n_layers=n_layers)\n",
    "neural_ode = NeuralODE(odefunc=odefunc, t=torch.tensor([0.0, 1.0]), solver=\"euler\")\n",
    "path = \"model_checkpoint_limit_node.ckpt\"\n",
    "lightning_model = TrainModel(model=neural_ode, learning_rate=learning_rate, path=path)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54364185-0c2f-433c-9277-17d4419aa82b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "length = X_test.shape[1] // n_test\n",
    "HX_test = []\n",
    "HU_test = []\n",
    "for i in range(n_test):\n",
    "    HX_test.append(X_test[:, i*length:(i+1)*length])\n",
    "    HU_test.append(U_test[:, i*length:(i+1)*length])\n",
    "HX_test = np.stack([HX_test[idx].T for idx in range(n_test)], axis=0)\n",
    "HU_test = np.stack([HU_test[idx].T for idx in range(n_test)], axis=0)\n",
    "test_dataset = TensorDataset(torch.tensor(HX_test, dtype=torch.float32), torch.tensor(HU_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=9999, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b65bcc7-4cda-4e60-8fe3-8b08b994f587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:10<00:00,  0.10it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.05708123371005058\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.05708123371005058}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.test(lightning_model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
