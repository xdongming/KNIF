{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import math\n",
    "from pydmd import DMD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a57628-6d4f-47de-842f-e5d20fae90a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualFlow(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_layers, input_dim=0, dropout=0, LDJ=False, block_id=0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_dim = input_dim\n",
    "        self.LDJ = LDJ\n",
    "        self.block_id = block_id\n",
    "\n",
    "        flip = (block_id % 2 == 0)\n",
    "        self.flow = Flow(dim, hidden_dim, flip=flip)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        x_e = x\n",
    "        if not reverse:\n",
    "            y = self.flow(x_e, reverse=False)\n",
    "            logdet = 0\n",
    "            return y, logdet\n",
    "        else:\n",
    "            y = self.flow(x_e, reverse=True)\n",
    "            return y\n",
    "\n",
    "class Flow(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_dim, flip=False):\n",
    "        super().__init__()\n",
    "        self.coupling = AffineCoupling(in_channel, hidden_dim, flip)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        return self.coupling(x, reverse)\n",
    "\n",
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, flip=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.flip = flip\n",
    "\n",
    "        self.split_idx = dim // 2\n",
    "        self.rest_dim = dim - self.split_idx\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.split_idx, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.rest_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        if self.flip:\n",
    "            x2, x1 = torch.split(x, [self.rest_dim, self.split_idx], dim=-1)\n",
    "        else:\n",
    "            x1, x2 = torch.split(x, [self.split_idx, self.rest_dim], dim=-1)\n",
    "\n",
    "        h = self.net(x1)\n",
    "        s, t = torch.chunk(h, 2, dim=-1)\n",
    "        s = torch.tanh(s)\n",
    "\n",
    "        if not reverse:\n",
    "            y2 = x2 * torch.exp(s) + t\n",
    "        else:\n",
    "            y2 = (x2 - t) * torch.exp(-s)\n",
    "\n",
    "        if self.flip:\n",
    "            return torch.cat([y2, x1], dim=-1)\n",
    "        else:\n",
    "            return torch.cat([x1, y2], dim=-1)\n",
    "    \n",
    "class InvertibleNN(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_blocks, n_layers, input_dim=0, dropout=0, LDJ=False):\n",
    "        super(InvertibleNN, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        self.blocks = nn.ModuleList([ResidualFlow(self.dim, self.hidden_dim, self.n_layers, self.input_dim, dropout, LDJ, block_id=i) for i in range(self.n_blocks)])\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        if not reverse:\n",
    "            ldj_total = 0\n",
    "            for block in self.blocks:\n",
    "                x, ldj = block(x, reverse)\n",
    "                ldj_total += ldj\n",
    "            return x, ldj_total\n",
    "        else:\n",
    "            for block in reversed(self.blocks):\n",
    "                x = block(x, reverse)\n",
    "            return x\n",
    "    \n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, inn_model, input_dim, lifted_dim):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.inn_model = inn_model  \n",
    "        self.lifted_dim = lifted_dim\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        x = x.float()\n",
    "        if not reverse:\n",
    "            zero_pad = torch.zeros(x.shape[0], x.shape[1], self.lifted_dim, device=x.device)\n",
    "            x = torch.cat((x, zero_pad), dim=-1)\n",
    "            x, ldj = self.inn_model(x, u, reverse)\n",
    "            return x, ldj\n",
    "        else:\n",
    "            x = self.inn_model(x, u, reverse)\n",
    "            x = x[:, :self.input_dim]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8996c880-1612-417a-ade9-b294f93ad045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dmd(model, X, rank):\n",
    "    GX_pred_list = []\n",
    "    GX_list = []\n",
    "    GX, ldj = model(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        GX_temp = GX[i, :, :].T\n",
    "        dmd = DMD(svd_rank=rank, exact=True, sorted_eigs='abs')\n",
    "        dmd.fit(GX_temp.cpu().detach().numpy())\n",
    "        GX_pred = dmd.reconstructed_data.real\n",
    "        GX_pred = np.array(GX_pred, dtype=np.float32)\n",
    "        GX_pred = torch.from_numpy(GX_pred).cuda()\n",
    "        GX_pred_list.append(GX_pred)\n",
    "        GX_list.append(GX_temp)\n",
    "    GX_pred = torch.cat(GX_pred_list, dim=-1)\n",
    "    GX = torch.cat(GX_list, dim=-1)\n",
    "\n",
    "    return GX, GX_pred, ldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bede68be-e48a-4205-b695-7cc047d892cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "    def __init__(self, model, rank, learning_rate=1e-3, lamb=1, path=\"model_checkpoint_dw\"):\n",
    "        super(TrainModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.best_val_loss = float('inf') \n",
    "        self.validation_outputs = []\n",
    "        self.lamb = lamb\n",
    "        self.train_losses = []\n",
    "        self.rank = rank\n",
    "        self.path = path+'.ckpt'\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch = batch[0]\n",
    "        GY, GY_pred, ldj = dmd(self.model, X_batch, self.rank)\n",
    "\n",
    "        loss_lin = self.criterion(GY, GY_pred)\n",
    "        loss_LDJ = ldj / X_batch.numel()\n",
    "\n",
    "        loss = loss_lin - self.lamb * loss_LDJ\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, _ = dmd(self.model, Z_batch, self.rank)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, reverse=True)\n",
    "        valid_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.validation_outputs.append(valid_loss)\n",
    "        self.log('val_loss', valid_loss)\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, _ = dmd(self.model, Z_batch, self.rank)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, reverse=True)\n",
    "        test_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.log('test_loss', test_loss)\n",
    "        return test_loss\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        if self.trainer.is_global_zero: \n",
    "            if os.path.exists(\"loss_log.txt\"):\n",
    "                os.remove(\"loss_log.txt\")\n",
    "            if os.path.exists(self.path):\n",
    "                os.remove(self.path)\n",
    "    \n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        with torch.no_grad():  \n",
    "            for name, module in self.model.named_modules():  \n",
    "                if isinstance(module, nn.Linear): \n",
    "                    if name == \"linear\":  \n",
    "                        continue\n",
    "                    weight = module.weight  \n",
    "                    sigma_max = torch.norm(weight, p=2)  \n",
    "                    if sigma_max > 1:  \n",
    "                        scale = (1 - 1e-3) / sigma_max\n",
    "                        module.weight.data *= scale  \n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        if os.path.exists(self.path):\n",
    "            best_state_dict = torch.load(self.path)[\"state_dict\"]\n",
    "            self.load_state_dict(best_state_dict)\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.is_global_zero:  \n",
    "            avg_train_loss = self.trainer.callback_metrics.get(\"train_loss\")\n",
    "            if avg_train_loss is not None:\n",
    "                self.train_losses.append(avg_train_loss.item())  \n",
    "                print(f\"Epoch {self.current_epoch}: Average Training Loss = {avg_train_loss.item()}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_outputs).mean()  \n",
    "        self.log('avg_val_loss', avg_val_loss)\n",
    "        self.validation_outputs.clear()\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        with open(\"loss_log.txt\", \"a\") as f:\n",
    "            f.write(f\"{avg_val_loss.item()}\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-08,\n",
    "                                            weight_decay=0)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #     optimizer,\n",
    "        #     mode='min',\n",
    "        #     factor=0.5,\n",
    "        #     patience=5,\n",
    "        #     cooldown=1\n",
    "        # )\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=1,\n",
    "            gamma=0.92\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",  \n",
    "            },\n",
    "            \"gradient_clip_val\": 1.0,  \n",
    "            \"gradient_clip_algorithm\": \"norm\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b6014d-e3a5-4d46-981b-0b39821bf013",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 1 \n",
    "hidden_dim = 10 \n",
    "input_dim = 0\n",
    "n_blocks = 3  \n",
    "n_layers = 1\n",
    "n_feature = 5\n",
    "rank = 3\n",
    "batch_size = 512\n",
    "n_train = 10000\n",
    "n_valid = 1000\n",
    "n_test = 1000\n",
    "dropout = 0\n",
    "num_epochs = 100  \n",
    "lamb = 1e-3\n",
    "learning_rate = 1e-3 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6874831a-16e4-4744-8cc9-1cf2c819a392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('single_train.csv', header=None).values\n",
    "X_valid = pd.read_csv('single_valid.csv', header=None).values\n",
    "X_test = pd.read_csv('single_test.csv', header=None).values\n",
    "\n",
    "length = X_train.shape[1] // n_train\n",
    "H_train = []\n",
    "for i in range(n_train):\n",
    "    H_train.append(X_train[:, i*length:(i+1)*length])\n",
    "H_train = np.stack([H_train[idx].T for idx in range(n_train)], axis=0)\n",
    "H_valid = []\n",
    "for i in range(n_valid):\n",
    "    H_valid.append(X_valid[:, i*length:(i+1)*length])\n",
    "H_valid = np.stack([H_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "train_dataset = TensorDataset(torch.tensor(H_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_dataset = TensorDataset(torch.tensor(H_valid))\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=99999, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "X_result = np.concatenate([X_train, X_test, X_valid], axis=-1)\n",
    "Xmax = torch.tensor(np.max(X_result, axis=-1), dtype=torch.float)\n",
    "Xmin = torch.tensor(np.min(X_result, axis=-1), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18639093-8bd2-44b5-82b7-ad2fabbe46d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "path = \"model_checkpoint_single_flowdmd\"\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    # monitor=\"avg_val_loss\",  \n",
    "    monitor=\"train_loss\",   \n",
    "    dirpath=\"./\",  \n",
    "    filename=path, \n",
    "    save_top_k=1,  \n",
    "    mode=\"min\",   \n",
    ")\n",
    "inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature)\n",
    "lightning_model = TrainModel(model=model, rank=rank, learning_rate=learning_rate, lamb=lamb, path=path)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs, callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8abde0b2-c523-4bad-830f-ae0a236d0f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature)\n",
    "path = \"model_checkpoint_single_flowdmd.ckpt\"\n",
    "lightning_model = TrainModel.load_from_checkpoint(path, model=model, rank=rank, learning_rate=learning_rate, map_location=\"cpu\")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54364185-0c2f-433c-9277-17d4419aa82b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "length = X_test.shape[1] // n_test\n",
    "H_test = []\n",
    "for i in range(n_test):\n",
    "    H_test.append(X_test[:, i*length:(i+1)*length])\n",
    "H_test = np.stack([H_test[idx].T for idx in range(n_test)], axis=0)\n",
    "test_dataset = TensorDataset(torch.tensor(H_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=9999, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b65bcc7-4cda-4e60-8fe3-8b08b994f587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA H100 80GB HBM3') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 4 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           2.0480878353118896\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2.0480878353118896}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.test(lightning_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c46516d-2760-44f1-b2f9-96733ad74163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "traj = H_test[134, :61, :].reshape(1, 61, 1)\n",
    "GY, GY_pred, _ = dmd(lightning_model.model, torch.tensor(traj), rank)\n",
    "X_recons = lightning_model.model(GY_pred.cpu().T, reverse=True).T.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b17b57f3-1799-4554-88a2-ed7b5fbe4954",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "t = np.linspace(0.01, 0.61, num=X_recons.shape[1])\n",
    "median_traj = X_recons\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "plt.plot(t, median_traj[0, :], color=\"blue\", linewidth=1.5, alpha=0.6, label='Median')\n",
    "\n",
    "plt.scatter(t[::1], traj[0, 0:X_recons.shape[1]:1, 0], color='red', s=8, alpha=0.8, linewidths=1.0, label='Test')\n",
    "\n",
    "# plt.plot(smooth_x, smooth_y, color=\"#0072B2\", linewidth=1.5, label='Reconstructed', zorder=1)\n",
    "\n",
    "# plt.scatter(\n",
    "#     t, X_traj[0, 1:751, 0]\n",
    "#     facecolors='none',\n",
    "#     edgecolors='#DAA520',\n",
    "#     s=30,\n",
    "#     linewidth=1.5,\n",
    "#     label='Test',\n",
    "#     zorder=2\n",
    "# )\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"c3.svg\", format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
