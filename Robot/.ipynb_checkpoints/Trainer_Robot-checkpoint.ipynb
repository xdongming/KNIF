{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import math\n",
    "from pydmd import DMD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a57628-6d4f-47de-842f-e5d20fae90a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualFlow(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, input_dim=0, dropout=0, LDJ=False):\n",
    "        super(ResidualFlow, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.LDJ = LDJ\n",
    "        self.dropout = dropout\n",
    "        self.n_layers = 1\n",
    "        \n",
    "        layers = [nn.Linear(self.dim + self.dim * (self.input_dim > 0), self.hidden_dim), nn.ReLU()]\n",
    "        for _ in range(self.n_layers):\n",
    "            layers.append(nn.Linear(self.hidden_dim, self.hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        layers.append(nn.Linear(self.hidden_dim, self.dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        if self.input_dim > 0:\n",
    "            self.cheby = nn.Linear(self.input_dim, self.dim - self.input_dim)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        def func(x_, u_):\n",
    "            x_e = torch.cat((x_, u_), dim=-1) if u is not None else x_\n",
    "            return self.net(x_e)\n",
    "        if u is not None:\n",
    "            u = F.tanh(u) / (1+1e-3)\n",
    "            chebyshev = torch.cos(self.cheby(torch.arccos(u)))\n",
    "            u = torch.cat((u, chebyshev), dim=-1)\n",
    "        if not reverse:   \n",
    "            y = x + func(x, u)\n",
    "            if self.LDJ:\n",
    "                x = x.view(-1, x.shape[-1])\n",
    "                u = u.view(-1, u.shape[-1]) if u is not None else None\n",
    "                jacobian = vmap(jacrev(func))(x, u)\n",
    "                jacobian = jacobian.clone() \n",
    "                jacobian.diagonal(dim1=-2, dim2=-1).add_(1.0)\n",
    "                _, logdet = torch.linalg.slogdet(jacobian)\n",
    "                logdet = logdet.sum()\n",
    "            else:\n",
    "                logdet = 0\n",
    "            return y, logdet\n",
    "        else:\n",
    "            y = x\n",
    "            epsilon = 1e-6\n",
    "            det = 1\n",
    "            max_iter = 100\n",
    "            with torch.no_grad():\n",
    "                for _ in range(max_iter):\n",
    "                    y_temp = y\n",
    "                    y = x - func(y, u)\n",
    "                    det = torch.norm(y - y_temp, dim=-1).max()\n",
    "                    if det < epsilon:\n",
    "                        break  \n",
    "                # while det > epsilon:\n",
    "                #     y_temp = y\n",
    "                #     y = x - func(y)\n",
    "                #     det = torch.norm(y - y_temp, dim=1).max()\n",
    "            return y\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for name, module in self.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if 'cheby' in name:\n",
    "                    lambda_s = 5\n",
    "                    module.weight.data = torch.distributions.exponential.Exponential(lambda_s).sample(module.weight.shape)\n",
    "                else:\n",
    "                    nn.init.xavier_uniform_(module.weight)\n",
    "                    if module.bias is not None:\n",
    "                        nn.init.zeros_(module.bias)\n",
    "\n",
    "class InvertibleNN(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_blocks, input_dim=0, dropout=0, LDJ=False):\n",
    "        super(InvertibleNN, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_blocks = n_blocks\n",
    "        self.input_dim = input_dim\n",
    "        self.blocks = nn.ModuleList([ResidualFlow(self.dim, self.hidden_dim, self.input_dim, dropout, LDJ) for _ in range(self.n_blocks)])\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        if not reverse:\n",
    "            ldj_total = 0\n",
    "            for block in self.blocks:\n",
    "                x, ldj = block(x, u, reverse)\n",
    "                ldj_total += ldj\n",
    "            return x, ldj_total\n",
    "        else:\n",
    "            for block in reversed(self.blocks):\n",
    "                x = block(x, u, reverse)\n",
    "            return x\n",
    "    \n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, inn_model, input_dim, lifted_dim, Xmax, Xmin):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.inn_model = inn_model  \n",
    "        self.Xmax = Xmax\n",
    "        self.Xmin = Xmin\n",
    "        self.dropout = nn.Dropout(p=inn_model.blocks[0].dropout)\n",
    "        self.linear = nn.Linear(input_dim, lifted_dim, bias=False)  \n",
    "        self.K = nn.Parameter(torch.randn(input_dim + lifted_dim, input_dim + lifted_dim), requires_grad=True)\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        x = x.float()\n",
    "        Xmax = self.Xmax.to(x.device)\n",
    "        Xmin = self.Xmin.to(x.device)\n",
    "        if not reverse:\n",
    "            x = (x - Xmin) / (Xmax - Xmin)\n",
    "            chebyshev = torch.cos(self.linear(torch.arccos(x)))\n",
    "            x = torch.cat((x, chebyshev), dim=-1)\n",
    "            # x = self.dropout(x)\n",
    "            x, ldj = self.inn_model(x, u, reverse)\n",
    "            return x, ldj\n",
    "        else:\n",
    "            x = self.inn_model(x, u, reverse)\n",
    "            x = x[:, :self.input_dim]\n",
    "            x = (Xmax - Xmin) * x + Xmin\n",
    "            return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        lambda_s = 5\n",
    "        self.linear.weight.data = torch.distributions.exponential.Exponential(lambda_s).sample(self.linear.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8996c880-1612-417a-ade9-b294f93ad045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dmd(model, X, U):\n",
    "    GX_pred_list = []\n",
    "    GX_list = []\n",
    "    U_list = []\n",
    "    GX, ldj = model(X, U.float())\n",
    "    for i in range(X.shape[0]):\n",
    "        GX_temp = GX[i, :, :].T\n",
    "        GX_pred = model.K @ GX_temp[:, :-1]\n",
    "        GX_pred_list.append(GX_pred)\n",
    "        GX_list.append(GX_temp[:, 1:])\n",
    "        U_list.append(U[i, 1:, :].T)\n",
    "    GX_pred = torch.cat(GX_pred_list, dim=-1)\n",
    "    GX = torch.cat(GX_list, dim=1)\n",
    "    U = torch.cat(U_list, dim=-1)\n",
    "\n",
    "    return GX, GX_pred, U, ldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bede68be-e48a-4205-b695-7cc047d892cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3, lamb=1, path=\"model_checkpoint_NP\"):\n",
    "        super(TrainModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.best_val_loss = float('inf')  \n",
    "        self.validation_outputs = []\n",
    "        self.lamb = lamb\n",
    "        self.train_losses = []\n",
    "        self.path = path+'.ckpt'\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch, U_batch = batch\n",
    "        GY, GY_pred, _, ldj = dmd(self.model, X_batch, U_batch)\n",
    "\n",
    "        loss_lin = self.criterion(GY, GY_pred.detach())\n",
    "        loss_LDJ = ldj / X_batch.numel()\n",
    "\n",
    "        loss = loss_lin - self.lamb * loss_LDJ\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        Z_batch, U_batch = batch\n",
    "        Z1, Z_pred, U, _ = dmd(self.model, Z_batch, U_batch)\n",
    "        Z_pred = self.model(Z_pred.T, U.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, U.T, reverse=True)\n",
    "        valid_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.validation_outputs.append(valid_loss)\n",
    "        self.log('val_loss', valid_loss)\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        Z_batch, U_batch = batch\n",
    "        Z1, Z_pred, U, _ = dmd(self.model, Z_batch, U_batch)\n",
    "        Z_pred = self.model(Z_pred.T, U.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, U.T, reverse=True)\n",
    "        test_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.log('test_loss', test_loss)\n",
    "        return test_loss\n",
    "    \n",
    "    def on_train_batch_end(self, outputs, batch, batch_idx):\n",
    "        with torch.no_grad():  \n",
    "            for name, module in self.model.named_modules():  \n",
    "                if isinstance(module, nn.Linear): \n",
    "                    if name == \"linear\":  \n",
    "                        continue\n",
    "                    weight = module.weight  \n",
    "                    sigma_max = torch.linalg.norm(weight, ord=2)  \n",
    "                    if sigma_max >= 1 - 1e-2:  \n",
    "                        scale = (1 - 1e-2) / sigma_max\n",
    "                        module.weight.data *= scale\n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        if os.path.exists(self.path):\n",
    "            best_state_dict = torch.load(self.path)[\"state_dict\"]\n",
    "            self.load_state_dict(best_state_dict)\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        device = self.model.K.device\n",
    "        self.model.eval() \n",
    "        with torch.no_grad():\n",
    "            x_all = self.train_dataloader.dataset.tensors[0].to(device)  \n",
    "            u_all = self.train_dataloader.dataset.tensors[1].to(device)  \n",
    "\n",
    "            gx_all = self.model(x_all, u_all)[0].detach()[:, :-1, :] \n",
    "            gy_all = self.model(x_all, u_all)[0].detach()[:, 1:, :]\n",
    "\n",
    "            gx_all = gx_all.reshape(-1, gx_all.shape[-1])\n",
    "            gy_all = gy_all.reshape(-1, gy_all.shape[-1])\n",
    "\n",
    "        optimizer_K = torch.optim.Adam([self.model.K], lr=1e-3)\n",
    "        for _ in range(100):  \n",
    "            optimizer_K.zero_grad()\n",
    "            gx_pred = gx_all @ self.model.K\n",
    "            loss_K = self.criterion(gx_pred, gy_all)\n",
    "            loss_K.backward()\n",
    "            optimizer_K.step()\n",
    "            with torch.no_grad():\n",
    "                radius = torch.linalg.norm(self.model.K.data, ord=2)\n",
    "                if radius > 1.0:\n",
    "                    self.model.K.data /= radius\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_outputs).mean()  \n",
    "        self.log('avg_val_loss', avg_val_loss)\n",
    "        self.validation_outputs.clear()\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        with open(\"loss_log.txt\", \"a\") as f:\n",
    "            f.write(f\"{avg_val_loss.item()}\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        g_params = [p for n, p in self.model.named_parameters() if \"K\" not in n]\n",
    "        optimizer = torch.optim.AdamW(g_params, lr=self.learning_rate, weight_decay=1e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=100,\n",
    "            gamma=0.5\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",  \n",
    "            },\n",
    "            \"gradient_clip_val\": 1.0,  \n",
    "            \"gradient_clip_algorithm\": \"norm\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 6 \n",
    "hidden_dim = 80  \n",
    "input_dim = 6\n",
    "n_blocks = 3  \n",
    "n_feature = 14\n",
    "batch_size = 32\n",
    "# n_train = 6400\n",
    "n_train = 1110\n",
    "# n_valid = 1000\n",
    "n_test = 1\n",
    "dropout = 0\n",
    "num_epochs = 1000  \n",
    "lamb = 1e-3\n",
    "learning_rate = 1e-3  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874831a-16e4-4744-8cc9-1cf2c819a392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('y_train.csv', header=None).values\n",
    "# X_valid = pd.read_csv('Non_X_valid.csv', header=None).values\n",
    "X_test = pd.read_csv('y_test.csv', header=None).values\n",
    "U_train = pd.read_csv('u_train.csv', header=None).values\n",
    "# U_valid = pd.read_csv('Non_U_valid.csv', header=None).values\n",
    "U_test = pd.read_csv('u_test.csv', header=None).values\n",
    "\n",
    "length = X_train.shape[1] // n_train\n",
    "HX_train = []\n",
    "HU_train = []\n",
    "for i in range(n_train):\n",
    "    HX_train.append(X_train[:, i*length:(i+1)*length])\n",
    "    HU_train.append(U_train[:, i*length:(i+1)*length])\n",
    "HX_train = np.stack([HX_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HU_train = np.stack([HU_train[idx].T for idx in range(n_train)], axis=0)\n",
    "HX_test = []\n",
    "HU_test = []\n",
    "length2 = X_test.shape[1] // n_test\n",
    "for i in range(n_test):\n",
    "    HX_test.append(X_test[:, i*length2:(i+1)*length2])\n",
    "    HU_test.append(U_test[:, i*length2:(i+1)*length2])\n",
    "HX_test = np.stack([HX_test[idx].T for idx in range(n_test)], axis=0)\n",
    "HU_test = np.stack([HU_test[idx].T for idx in range(n_test)], axis=0)\n",
    "train_dataset = TensorDataset(torch.tensor(HX_train, dtype=torch.float32), torch.tensor(HU_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_dataset = TensorDataset(torch.tensor(HX_test, dtype=torch.float32), torch.tensor(HU_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=99999, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "X_result = np.concatenate([X_train, X_test], axis=-1)\n",
    "Xmax = torch.tensor(np.max(X_result, axis=-1), dtype=torch.float)\n",
    "Xmin = torch.tensor(np.min(X_result, axis=-1), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18639093-8bd2-44b5-82b7-ad2fabbe46d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "path = \"model_checkpoint_Robot\"\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    # monitor=\"avg_val_loss\",  \n",
    "    monitor=\"train_loss\",   \n",
    "    dirpath=\"./\",  \n",
    "    filename=path,\n",
    "    save_top_k=1,  \n",
    "    mode=\"min\",   \n",
    ")\n",
    "inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature, Xmax=Xmax, Xmin=Xmin)\n",
    "lightning_model = TrainModel(model=model, learning_rate=learning_rate, lamb=lamb, path=path)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_find_unused_parameters_true\", max_epochs=num_epochs, callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abde0b2-c523-4bad-830f-ae0a236d0f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature, Xmax=Xmax, Xmin=Xmin)\n",
    "path = \"model_checkpoint_Robot.ckpt\"\n",
    "lightning_model = TrainModel.load_from_checkpoint(path, model=model, learning_rate=learning_rate, map_location=\"cpu\")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65bcc7-4cda-4e60-8fe3-8b08b994f587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.test(lightning_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2349e24-07eb-4ab9-8eba-c5436072c26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_traj = HX_test\n",
    "U_traj = HU_test\n",
    "GY, GY_pred, U, _ = dmd(lightning_model.model, torch.tensor(X_traj, dtype=torch.float32), torch.tensor(U_traj, dtype=torch.float32))\n",
    "X_recons = lightning_model.model(GY_pred.T.cpu(), U.T, reverse=True).T.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8daebd-13f0-4eb0-af2e-e4d8bd106422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(X_traj[0, 1:, 0]-X_recons[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52931a-8f53-4359-86fc-bab225a3d99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(X_traj[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3291ee9a-8024-4310-89f3-6fa12bb848c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(X_recons[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bcec3-f608-4543-a256-fe86b1ffe9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_test = pd.read_csv('y_mt_test.csv', header=None).values\n",
    "# U_test = pd.read_csv('u_mt_test.csv', header=None).values\n",
    "X_test = pd.read_csv('y_test.csv', header=None).values\n",
    "U_test = pd.read_csv('u_test.csv', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a61be-71da-40d5-96e5-c98228cc1099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, _ = lightning_model.model(torch.tensor(X_test.T, dtype=torch.float32).unsqueeze(0), torch.tensor(U_test.T, dtype=torch.float32).unsqueeze(0))\n",
    "x_recons = dmd_model.predict(X[0, :-1, :].T.detach().numpy())\n",
    "X_recons = lightning_model.model(torch.tensor(x_recons.T, dtype=torch.float32), torch.tensor(U_test[:, 1:].T, dtype=torch.float32), reverse=True).T.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00fbff-04e6-4ca6-98f0-eaba15b04977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((X_test[0, 1:]-X_recons[0, :])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b690341-a0a0-48ce-b399-02977f7d6b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "100 * (np.linalg.norm(X_test[0, 1:]-X_recons[0, :]) / np.linalg.norm(X_test[0, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314de7f2-f990-40d1-973b-32c8a6d3c8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test[0, 1:]-X_recons[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e2b17-95cc-48bc-a03a-a73c6bb54f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(X_test[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f26538a-8f6a-4ad3-afdd-aaa3100a414c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(X_recons[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a4fe6-3b49-45b0-80fb-e6f65d6fda97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "arial_font = FontProperties(fname=\"/root/.fonts/arial.ttf\")\n",
    "\n",
    "scatter_color = '#D55E00'   \n",
    "line_color = '#009E73'      \n",
    "\n",
    "interp_factor = 2  \n",
    "\n",
    "x_raw = np.arange(X_recons.shape[1])\n",
    "x_new = np.linspace(x_raw.min(), x_raw.max(), X_recons.shape[1] * interp_factor)\n",
    "\n",
    "f1 = interp1d(x_raw, X_recons[0], kind='cubic')\n",
    "f2 = interp1d(x_raw, X_recons[1], kind='cubic')\n",
    "smooth_x1 = f1(x_new)\n",
    "smooth_x2 = f2(x_new)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "plt.plot(smooth_x1, smooth_x2, color=line_color, linewidth=1.2, alpha=0.9, label='Reconstructed')\n",
    "\n",
    "plt.scatter(X_traj[0, :, 0], X_traj[0, :, 1],\n",
    "            s=14, facecolors='none', edgecolors=scatter_color,\n",
    "            linewidths=1.0, alpha=0.85, label='Test')\n",
    "\n",
    "plt.xlabel('$x_1$', fontsize=12)\n",
    "plt.ylabel('$x_2$', fontsize=12)\n",
    "plt.xticks(fontsize=8, fontproperties=arial_font)\n",
    "plt.yticks(fontsize=8, fontproperties=arial_font)\n",
    "plt.legend(\n",
    "    loc='lower center',\n",
    "    bbox_to_anchor=(0.5, 1.02),\n",
    "    borderaxespad=0.3,\n",
    "    ncol=2,\n",
    "    frameon=False,\n",
    "    fontsize=8,\n",
    "    prop=arial_font\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"input1.svg\", format='svg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73717888-49d8-4aea-85c6-66e2309b99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traj = 1000\n",
    "dim = 2\n",
    "rmse_values = np.zeros(61)\n",
    "for i in range(num_traj):\n",
    "    traj = HX_test[i, :61, :].reshape(1, 61, 2)\n",
    "    GY, GY_pred, U, _ = dmd(lightning_model.model, torch.tensor(traj, dtype=torch.float32), torch.tensor(HU_test[i, :61, :], dtype=torch.float32).reshape(1, 61, 1), rank)\n",
    "    X_recons = lightning_model.model(GY_pred.cpu().T, U.T, reverse=True).detach().numpy()\n",
    "    error = np.sum((X_recons - traj.squeeze()) ** 2, axis=1)  \n",
    "    rmse_values += error\n",
    "rmse_values = np.sqrt(rmse_values / (num_traj * dim)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37895795-f960-4d9a-a206-66acf0703efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = np.linspace(0, 60*0.1, 61, traj.shape[1])\n",
    "plt.semilogy(t, rmse_values)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Reconstructed Error on Test Set')\n",
    "plt.savefig(\"controlled2.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78546d-4a45-4e73-9101-c4472c298a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_traj = torch.tensor(pd.read_csv('autonomous.csv', header=None).values.T, dtype=torch.float32).unsqueeze(0)\n",
    "U_traj = torch.tensor(np.zeros(X_traj.squeeze(0).shape[:-1] + (1,)), dtype=torch.float32)\n",
    "GX_temp, ldj = model(torch.tensor(X_traj.squeeze(0), dtype=torch.float32), U_traj)\n",
    "GX_temp = GX_temp.T\n",
    "dmd = DMD(svd_rank=rank, exact=True, sorted_eigs='abs')\n",
    "dmd.fit(GX_temp.cpu().detach().numpy())\n",
    "GX_pred = dmd.reconstructed_data.real\n",
    "GX_pred = np.array(GX_pred, dtype=np.float32)\n",
    "GX_pred = torch.from_numpy(GX_pred).cuda()\n",
    "X_recons = lightning_model.model(GX_pred.cpu().T, U_traj, reverse=True).T.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b8917-e5dd-4164-b1b8-dd572450af4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(X_traj[0, :, 0], X_traj[0, :, 1], label='Test')\n",
    "plt.plot(X_recons[0, :], X_recons[1, :], label='Reconstructed')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.legend()\n",
    "plt.title('Reconstructed Trajectory Without Input')\n",
    "plt.savefig(\"controlled3.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d6262-a3aa-46d2-bddd-1bfa187afd73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
