{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050e659e-20f4-4b07-b724-21cb2ef26b76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import math\n",
    "from pydmd import DMD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b602e280-468b-4cf2-a863-55ec84de6de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualFlow(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_layers, input_dim=0, dropout=0, LDJ=False, block_id=0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_dim = input_dim\n",
    "        self.LDJ = LDJ\n",
    "\n",
    "        self.flow = Flow(dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        x_e = x\n",
    "        if not reverse:\n",
    "            y = self.flow(x_e, reverse=False)\n",
    "            logdet = 0  \n",
    "            return y, logdet\n",
    "        else:\n",
    "            y = self.flow(x_e, reverse=True)\n",
    "            return y\n",
    "\n",
    "class Flow(nn.Module):\n",
    "    def __init__(self, in_channel, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.coupling = AffineCoupling(in_channel, hidden_dim)\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        x = self.coupling(x, reverse)\n",
    "        return x\n",
    "\n",
    "class AffineCoupling(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.split_idx = dim // 2\n",
    "        self.rest_dim = dim - self.split_idx\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(self.split_idx, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, self.rest_dim * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, reverse=False):\n",
    "        x1, x2 = torch.split(x, [self.split_idx, self.rest_dim], dim=-1)\n",
    "        h = self.net(x1)\n",
    "        s, t = torch.chunk(h, 2, dim=-1)\n",
    "        s = torch.tanh(s)\n",
    "\n",
    "        if not reverse:\n",
    "            y2 = x2 * torch.exp(s) + t\n",
    "        else:\n",
    "            y2 = (x2 - t) * torch.exp(-s)\n",
    "\n",
    "        return torch.cat([x1, y2], dim=-1)\n",
    "    \n",
    "class InvertibleNN(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, n_blocks, n_layers, input_dim=0, dropout=0, LDJ=False):\n",
    "        super(InvertibleNN, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.input_dim = input_dim\n",
    "        self.blocks = nn.ModuleList([ResidualFlow(self.dim, self.hidden_dim, self.n_layers, self.input_dim, dropout, LDJ, block_id=i) for i in range(self.n_blocks)])\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        if not reverse:\n",
    "            ldj_total = 0\n",
    "            for block in self.blocks:\n",
    "                x, ldj = block(x, reverse)\n",
    "                ldj_total += ldj\n",
    "            return x, ldj_total\n",
    "        else:\n",
    "            for block in reversed(self.blocks):\n",
    "                x = block(x, reverse)\n",
    "            return x\n",
    "    \n",
    "class CombinedNetwork(nn.Module):\n",
    "    def __init__(self, inn_model, input_dim, lifted_dim, Xmax, Xmin):\n",
    "        super(CombinedNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.inn_model = inn_model  \n",
    "        self.Xmax = Xmax\n",
    "        self.Xmin = Xmin\n",
    "        self.lifted_dim = lifted_dim\n",
    "    \n",
    "    def forward(self, x, u=None, reverse=False):\n",
    "        x = x.float()\n",
    "        Xmax = self.Xmax.to(x.device)\n",
    "        Xmin = self.Xmin.to(x.device)\n",
    "        if not reverse:\n",
    "            zero_pad = torch.zeros(x.shape[0], x.shape[1], self.lifted_dim, device=x.device)\n",
    "            x = torch.cat((x, zero_pad), dim=-1)\n",
    "            x, ldj = self.inn_model(x, u, reverse)\n",
    "            return x, ldj\n",
    "        else:\n",
    "            x = self.inn_model(x, u, reverse)\n",
    "            x = x[:, :self.input_dim]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f82eb2-731c-4827-9194-6a65f9842548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dmd(model, X, rank):\n",
    "    GX_pred_list = []\n",
    "    GX_list = []\n",
    "    GX, ldj = model(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        GX_temp = GX[i, :, :].T\n",
    "        dmd = DMD(svd_rank=rank, exact=True, sorted_eigs='abs')\n",
    "        dmd.fit(GX_temp.cpu().detach().numpy())\n",
    "        GX_pred = dmd.reconstructed_data.real\n",
    "        GX_pred = np.array(GX_pred, dtype=np.float32)\n",
    "        GX_pred = torch.from_numpy(GX_pred).cuda()\n",
    "        GX_pred_list.append(GX_pred)\n",
    "        GX_list.append(GX_temp)\n",
    "    GX_pred = torch.cat(GX_pred_list, dim=-1)\n",
    "    GX = torch.cat(GX_list, dim=1)\n",
    "\n",
    "    return GX, GX_pred, ldj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43d5609-1fb3-4f6c-a55b-23216203377a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainModel(pl.LightningModule):\n",
    "    def __init__(self, model, rank, learning_rate=1e-3, lamb=1, path=\"model_checkpoint_NP\"):\n",
    "        super(TrainModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.best_val_loss = float('inf')  \n",
    "        self.validation_outputs = []\n",
    "        self.lamb = lamb\n",
    "        self.train_losses = []\n",
    "        self.rank = rank\n",
    "        self.path = path+'.ckpt'\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch = batch[0]\n",
    "        GY, GY_pred, ldj = dmd(self.model, X_batch, self.rank)\n",
    "\n",
    "        loss_lin = self.criterion(GY, GY_pred)\n",
    "        loss_LDJ = ldj / X_batch.numel()\n",
    "\n",
    "        loss = loss_lin - self.lamb * loss_LDJ\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, _ = dmd(self.model, Z_batch, self.rank)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, reverse=True)\n",
    "        valid_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.validation_outputs.append(valid_loss)\n",
    "        self.log('val_loss', valid_loss)\n",
    "        return valid_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        Z_batch = batch[0]\n",
    "        Z1, Z_pred, _ = dmd(self.model, Z_batch, self.rank)\n",
    "        Z_pred = self.model(Z_pred.T, reverse=True)\n",
    "        Z1 = self.model(Z1.T, reverse=True)\n",
    "        test_loss = self.criterion(Z_pred, Z1)\n",
    "\n",
    "        self.log('test_loss', test_loss)\n",
    "        return test_loss\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        if self.trainer.is_global_zero: \n",
    "            if os.path.exists(\"loss_log.txt\"):\n",
    "                os.remove(\"loss_log.txt\")\n",
    "            if os.path.exists(self.path):\n",
    "                os.remove(self.path)\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.is_global_zero: \n",
    "            avg_train_loss = self.trainer.callback_metrics.get(\"train_loss\")\n",
    "            if avg_train_loss is not None:\n",
    "                self.train_losses.append(avg_train_loss.item())  \n",
    "                print(f\"Epoch {self.current_epoch}: Average Training Loss = {avg_train_loss.item()}\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_val_loss = torch.stack(self.validation_outputs).mean()  \n",
    "        self.log('avg_val_loss', avg_val_loss)\n",
    "        self.validation_outputs.clear()\n",
    "        print(f\"Validation loss: {avg_val_loss}\")\n",
    "        with open(\"loss_log.txt\", \"a\") as f:\n",
    "            f.write(f\"{avg_val_loss.item()}\\n\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, eps=1e-08,\n",
    "                                            weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=1,\n",
    "            gamma=0.92\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",  \n",
    "            },\n",
    "            \"gradient_clip_val\": 1.0, \n",
    "            \"gradient_clip_algorithm\": \"norm\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd91c08d-d518-4473-85da-d92ab90d7dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim = 3  \n",
    "hidden_dim = 40  \n",
    "input_dim = 0\n",
    "n_blocks = 3  \n",
    "n_layers = 1\n",
    "n_feature = 2\n",
    "rank = 3\n",
    "batch_size = 512\n",
    "n_train = 10000\n",
    "n_valid = 1000\n",
    "n_test = 1000\n",
    "dropout = 0\n",
    "num_epochs = 20  \n",
    "lamb = 0\n",
    "learning_rate = 1e-3 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b85bfb-a714-4750-9b83-03efae756757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('KO_sample_train.csv', header=None).values\n",
    "X_valid = pd.read_csv('KO_sample_valid.csv', header=None).values\n",
    "X_test = pd.read_csv('KO_sample_test.csv', header=None).values\n",
    "\n",
    "length = X_train.shape[1] // n_train\n",
    "H_train = []\n",
    "for i in range(n_train):\n",
    "    H_train.append(X_train[:, i*length:(i+1)*length])\n",
    "H_train = np.stack([H_train[idx].T for idx in range(n_train)], axis=0)\n",
    "H_valid = []\n",
    "for i in range(n_valid):\n",
    "    H_valid.append(X_valid[:, i*length:(i+1)*length])\n",
    "H_valid = np.stack([H_valid[idx].T for idx in range(n_valid)], axis=0)\n",
    "\n",
    "X_result = np.concatenate([X_train, X_test, X_valid], axis=-1)\n",
    "Xmax = torch.tensor(np.max(X_result, axis=-1), dtype=torch.float)\n",
    "Xmin = torch.tensor(np.min(X_result, axis=-1), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdccacf-ea40-434b-b51d-e2fd785f00e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sample_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "# sample_list = [1]\n",
    "for i in sample_list:\n",
    "    path = f\"model_checkpoint_KO_sample_{i}\"\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"avg_val_loss\",  \n",
    "        dirpath=\"./\", \n",
    "        filename=path, \n",
    "        save_top_k=1, \n",
    "        mode=\"min\",    \n",
    "    )\n",
    "    H_train_tensor = torch.tensor(H_train[:, 0:11*i:i, :], dtype=torch.float32)\n",
    "    train_dataset = TensorDataset(H_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    H_valid_tensor = torch.tensor(H_valid[:, 0:11*i:i, :], dtype=torch.float32)\n",
    "    valid_dataset = TensorDataset(H_valid_tensor)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, LDJ=lamb>0)\n",
    "    model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature, Xmax=Xmax, Xmin=Xmin)\n",
    "    lightning_model = TrainModel(model=model, rank=rank, learning_rate=learning_rate, lamb=lamb, path=path)\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs, callbacks=[checkpoint_callback])\n",
    "\n",
    "    trainer.fit(lightning_model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1118f8d8-8d86-40c3-a525-4593ef2a3a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature, Xmax=Xmax, Xmin=Xmin)\n",
    "path = \"model_checkpoint_KO_sample_1.ckpt\"\n",
    "lightning_model = TrainModel.load_from_checkpoint(path, model=model, rank=rank, learning_rate=learning_rate, map_location=\"cpu\")\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b72a1b3f-f44f-4ca6-adf9-b9041b669839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "length = X_test.shape[1] // n_test\n",
    "H_test = []\n",
    "for i in range(n_test):\n",
    "    H_test.append(X_test[:, i*length:(i+1)*length])\n",
    "H_test = np.stack([H_test[idx].T for idx in range(n_test)], axis=0)\n",
    "test_dataset = TensorDataset(torch.tensor(H_test[:, 0:11*1:1, :], dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=9999, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5896a-4ebf-4f0b-a1d1-523e5d8d8526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "trainer.test(lightning_model, dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94052c-a9e7-457a-b50e-60c894f2eb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sample_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "error_list = []\n",
    "\n",
    "for i in sample_list:\n",
    "    path = f\"model_checkpoint_KO_sample_{i}.ckpt\"\n",
    "    inn_model = InvertibleNN(dim=dim+n_feature, hidden_dim=hidden_dim, n_blocks=n_blocks, n_layers=n_layers, input_dim=input_dim, dropout=dropout, LDJ=lamb>0)\n",
    "    model = CombinedNetwork(inn_model=inn_model, input_dim=dim, lifted_dim=n_feature, Xmax=Xmax, Xmin=Xmin)\n",
    "    lightning_model = TrainModel.load_from_checkpoint(path, model=model, rank=rank, learning_rate=learning_rate, map_location=\"cpu\")\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", devices=4, strategy=\"ddp_notebook\", max_epochs=num_epochs)\n",
    "    H_test_tensor = torch.tensor(H_test[:, 0:11*i:i, :], dtype=torch.float32)\n",
    "    test_dataset = TensorDataset(H_test_tensor)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=9999, shuffle=True)\n",
    "    error_list.append(trainer.test(lightning_model, dataloaders=test_loader)[0]['test_loss'])\n",
    "\n",
    "df = pd.DataFrame(error_list)\n",
    "df.to_csv(\"sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13cf3f4a-5760-445c-8b14-ac89ec1dd9da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6763868071478782e-11,\n",
       " 2.0389469279624706e-10,\n",
       " 1.1766696506043672e-09,\n",
       " 6.984332667769877e-09,\n",
       " 2.9395057055126017e-08,\n",
       " 7.497171594650354e-08,\n",
       " 2.5459891617174435e-07,\n",
       " 4.894876610705978e-07,\n",
       " 9.634899242882966e-07,\n",
       " 1.9518886347213993e-06,\n",
       " 0.00014339735207613558,\n",
       " 0.0013706623576581478,\n",
       " 0.005123998504132032,\n",
       " 0.009524507448077202,\n",
       " 0.013661797158420086,\n",
       " 0.017679421231150627,\n",
       " 0.009798080660402775,\n",
       " 0.11375629156827927,\n",
       " 0.014699549414217472]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
